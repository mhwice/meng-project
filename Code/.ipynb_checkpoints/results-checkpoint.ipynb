{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "from random import randint\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "from zipfile import ZipFile\n",
    "import imageio\n",
    "import time\n",
    "import statistics\n",
    "import editdistance\n",
    "import traceback\n",
    "import cProfile\n",
    "import LM.clean\n",
    "import LM.segment\n",
    "\n",
    "%matplotlib inline\n",
    "figure_size = 15\n",
    "plt.rcParams['figure.figsize'] = (figure_size, figure_size)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "from SegLink import datasets\n",
    "from SegLink.ssd_utils import load_weights\n",
    "from SegLink.ssd_data import InputGenerator, preprocess\n",
    "from SegLink.sl_model import SL512, SL512v2\n",
    "from SegLink.sl_utils import PriorUtil, rbox_to_polygon, polygon_to_rbox\n",
    "from SegLink.sl_metric import evaluate_results, fscore\n",
    "from SegLink.ssd_viz import plot_box, escape_latex\n",
    "from SegLink.ssd_training import Logger\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import SGD, Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "from CRNN.crnn_model import CRNN, CRNNv2\n",
    "from CRNN.crnn_data import InputGenerator, crop_words \n",
    "from CRNN.crnn_utils import alphabet87 as alphabet\n",
    "from CRNN.crnn_utils import decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background              0\n",
      "Text              7266338\n",
      "\n",
      "images             858749\n",
      "objects           7266338\n",
      "per image            8.46\n",
      "no annotation           0\n",
      "\n",
      "Background              0\n",
      "Text                42095\n",
      "\n",
      "images               4294\n",
      "objects             42095\n",
      "per image            9.80\n",
      "no annotation           0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from data_icdar2015ist import GTUtility\n",
    "# gt_util_test_2015 = GTUtility('data/ICDAR2015_IST/', test=True)\n",
    "\n",
    "# from data_icdar2015fst import GTUtility\n",
    "# gt_util_test_2013 = GTUtility('data/ICDAR2015_FST/', test=True, polygon=True)\n",
    "\n",
    "# print(gt_util_test_2013)\n",
    "# print(gt_util_test_2015)\n",
    "\n",
    "random.seed(1337)\n",
    "from data_synthtext import GTUtility\n",
    "with open('gt_util_synthtext_seglink.pkl', 'rb') as f:\n",
    "    gt_util = pickle.load(f)\n",
    "# gt_util_train, gt_util_other = gt_util.split(gt_util, split=0.5)\n",
    "# gt_util_val, foo = gt_util.split(gt_util_other, split=0.03)\n",
    "# gt_util_test, bar = gt_util.split(foo, split=0.03)\n",
    "\n",
    "gt_util_train, gt_util_val = gt_util.split(gt_util, split=0.95)\n",
    "print(gt_util)\n",
    "gt_util_synth, foo = gt_util.split(gt_util, split=0.005)\n",
    "print(gt_util_synth)\n",
    "\n",
    "# print(gt_util_train)\n",
    "# print(gt_util_val)\n",
    "# print(gt_util_test)\n",
    "\n",
    "# testing_icdar2013_recognition_images, testing_icdar2013_recognition_image_names, testing_icdar2015_recognition_images, testing_icdar2015_recognition_image_names = datasets.load_testing_real_recognition_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### loading other datasets ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gts = glob.glob(\"./data/icdar_2013_focused_scene_text/localization/testing/gt/*.txt\")\n",
    "# # for g in gts:\n",
    "# textfile = open(gts[0], 'r')\n",
    "# textfile_data = textfile.readlines()\n",
    "# textfile.close()\n",
    "# gt = []\n",
    "# for l in range(len(textfile_data)):\n",
    "#     gt.append(textfile_data[l].split(\",\")[-1].rstrip().strip()[1:-1].lower())\n",
    "# print(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# gts = glob.glob(\"./data/icdar_2015_incidental_scene_text/localization/testing/gt/*.txt\")\n",
    "# gt = []\n",
    "# for g in gts:\n",
    "#     print(g)\n",
    "#     textfile = open(g, 'r')\n",
    "#     textfile_data = textfile.readlines()\n",
    "#     textfile.close()\n",
    "#     image_gt = []\n",
    "#     for l in range(len(textfile_data)):\n",
    "#         line = textfile_data[l].split(\",\")\n",
    "#         word = line[-1].rstrip().lower()\n",
    "#         if word == \"###\":\n",
    "#             continue\n",
    "#         else:\n",
    "#             image_gt.append(line)\n",
    "#     gt.append(image_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_util_test_2013.image_names[0].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SegLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3148: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "model = SL512()\n",
    "# model = SL512v2()\n",
    "prior_util = PriorUtil(model)\n",
    "image_size = model.image_size\n",
    "# synth\n",
    "# weights_path = './cps/sl/original_sl_synth/weights.001.h5'\n",
    "weights_path = './SegLink/checkpoints/original_sl_synth/weights.001.h5'\n",
    "# weights_path = './checkpointsw/PRETRAINED WEIGHTS/SegLink/201809231008_sl512_synthtext/weights.002.h5'\n",
    "# 2013\n",
    "# weights_path = './cps/sl/original_sl_2013/weights.1150.h5'\n",
    "# weights_path = './cps/sl/original_sl_2013/weights.998.h5'\n",
    "# 2015\n",
    "# weights_path = './cps/sl/original_sl_2015/weights.006.h5'\n",
    "load_weights(model, weights_path)\n",
    "checkdir = os.path.split(weights_path)[0]\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "##### CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer missing label_input\n",
      "layer missing input_length\n",
      "layer missing label_length\n",
      "layer missing ctc\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 256, 32, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 256, 32, 64)       640       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 128, 16, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 128, 16, 128)      73856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 64, 8, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 64, 8, 256)        295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 64, 8, 256)        590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 64, 4, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv4_11111 (DepthwiseConv2D (None, 64, 4, 256)        2304      \n",
      "_________________________________________________________________\n",
      "batchnorm111 (BatchNormaliza (None, 64, 4, 256)        1024      \n",
      "_________________________________________________________________\n",
      "act111 (Activation)          (None, 64, 4, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv4_22222 (Conv2D)         (None, 64, 4, 512)        131072    \n",
      "_________________________________________________________________\n",
      "batchnorm222 (BatchNormaliza (None, 64, 4, 512)        2048      \n",
      "_________________________________________________________________\n",
      "act222 (Activation)          (None, 64, 4, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv5_11111 (DepthwiseConv2D (None, 64, 4, 512)        4608      \n",
      "_________________________________________________________________\n",
      "batchnorm333 (BatchNormaliza (None, 64, 4, 512)        2048      \n",
      "_________________________________________________________________\n",
      "act333 (Activation)          (None, 64, 4, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv5_22222 (Conv2D)         (None, 64, 4, 512)        262144    \n",
      "_________________________________________________________________\n",
      "batchnorm444 (BatchNormaliza (None, 64, 4, 512)        2048      \n",
      "_________________________________________________________________\n",
      "act444 (Activation)          (None, 64, 4, 512)        0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 63, 2, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv6_1 (Conv2D)             (None, 62, 1, 512)        1049088   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 62, 512)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 62, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 62, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 62, 87)            44631     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 62, 87)            0         \n",
      "=================================================================\n",
      "Total params: 5,610,583\n",
      "Trainable params: 5,606,999\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_width = 256 \n",
    "input_height = 32\n",
    "# crnn_model = CRNN((input_width, input_height, 1), len(alphabet), prediction_only=True, gru=False)\n",
    "# load_weights(crnn_model, './cps/crnn/original_crnn_synth/weights.400000.h5')\n",
    "crnn_model = CRNNv2((input_width, input_height, 1), len(alphabet), prediction_only=True, gru=False)\n",
    "load_weights(crnn_model, './CRNN/checkpoints/our_crnn_synth/weights.080000.h5')\n",
    "# crnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SegLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 41s 3s/step\n",
      "Detection took 41.38807010650635 seconds\n",
      "For 16 frames\n"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "images = []\n",
    "images_orig = []\n",
    "data = []\n",
    "\n",
    "# gtu = gt_util_test_2013\n",
    "# gtu = gt_util_test_2015\n",
    "gtu = gt_util_synth\n",
    "# average = 0\n",
    "# np.random.seed(1337)\n",
    "# countr = 0\n",
    "# start = time.time()\n",
    "# for i in range(0, gtu.num_samples, 16):\n",
    "#     countr+=1\n",
    "#     img = cv2.imread(os.path.join(gtu.image_path, gtu.image_names[i]))\n",
    "#     preds = model.predict(np.asarray([preprocess(img, image_size)]), batch_size=1, verbose=1)\n",
    "#     h, w = image_size\n",
    "#     img = cv2.resize(img, (w,h), cv2.INTER_LINEAR).astype('float32')\n",
    "#     img = img[:, :, (2,1,0)]\n",
    "#     img /= 255\n",
    "#     images.append(img)\n",
    "#     gt_boxes = gtu.data[i]\n",
    "#     boxes = gtu.data[i]\n",
    "#     data.append(boxes)\n",
    "# end = time.time()    \n",
    "\n",
    "np.random.seed(1337)\n",
    "countr = 0\n",
    "start = time.time()\n",
    "# for i in range(0, gtu.num_samples, 16):\n",
    "for i in range(0, 16):\n",
    "    countr+=1\n",
    "    img = cv2.imread(os.path.join(gtu.image_path, gtu.image_names[i]))\n",
    "    images_orig.append(np.copy(img))\n",
    "    inputs.append(preprocess(img, image_size))\n",
    "    h, w = image_size\n",
    "    img = cv2.resize(img, (w,h), cv2.INTER_LINEAR).astype('float32')\n",
    "    img = img[:, :, (2,1,0)]\n",
    "    img /= 255\n",
    "    images.append(img)\n",
    "    boxes = gtu.data[i]\n",
    "    data.append(boxes)\n",
    "\n",
    "inputs = np.asarray(inputs)\n",
    "preds = model.predict(inputs, batch_size=1, verbose=1)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Detection took\", end-start, \"seconds\")\n",
    "print(\"For\", countr, \"frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(len(preds)):\n",
    "#     res = prior_util.decode(preds[k], segment_threshold=0.75, link_threshold=0.6)\n",
    "\n",
    "#     img_name = \"./icdar2015res/res_\" + gtu.image_names[k].split(\".\")[0] + \".txt\"\n",
    "#     print(img_name)\n",
    "    \n",
    "#     rboxes = res[:,:5]\n",
    "#     if len(rboxes) == 0:\n",
    "#         continue\n",
    "\n",
    "#     boxes = np.asarray([rbox_to_polygon(r) for r in rboxes])\n",
    "#     boxes = np.flip(boxes, axis=1)\n",
    "#     boxes = np.reshape(boxes, (-1, 8))\n",
    "\n",
    "#     boxes_mask_a = np.array([b[2] > b[3] for b in rboxes]) # width > height, in square world\n",
    "#     boxes_mask_b = np.array([not (np.any(b < 0) or np.any(b > 512)) for b in boxes]) # box inside image\n",
    "#     boxes_mask = np.logical_and(boxes_mask_a, boxes_mask_b)\n",
    "\n",
    "#     boxes = boxes[boxes_mask]\n",
    "#     rboxes = rboxes[boxes_mask]\n",
    "#     if len(boxes) == 0:\n",
    "#         boxes = np.empty((0,8))\n",
    "#     with open(img_name, \"w\") as text_file:\n",
    "#         write_string = \"\"\n",
    "#         for box in boxes:\n",
    "#             write_string = ','.join(str(int(e)) for e in box) + \"\\n\"\n",
    "#         text_file.write(write_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SegLink GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: 0.945 R: 0.917 F: 0.931 Seg: 0.6 Link: 0.5\n",
      "P: 0.944 R: 0.899 F: 0.921 Seg: 0.7 Link: 0.5\n",
      "P: 0.953 R: 0.851 F: 0.899 Seg: 0.8 Link: 0.5\n",
      "P: 0.899 R: 0.899 F: 0.899 Seg: 0.7 Link: 0.6\n",
      "P: 0.862 R: 0.929 F: 0.894 Seg: 0.6 Link: 0.6\n",
      "P: 0.935 R: 0.851 F: 0.891 Seg: 0.8 Link: 0.7\n",
      "P: 0.935 R: 0.851 F: 0.891 Seg: 0.8 Link: 0.6\n",
      "P: 0.868 R: 0.899 F: 0.883 Seg: 0.7 Link: 0.7\n",
      "P: 0.888 R: 0.851 F: 0.869 Seg: 0.8 Link: 0.8\n",
      "P: 0.954 R: 0.738 F: 0.832 Seg: 0.9 Link: 0.5\n",
      "P: 0.947 R: 0.738 F: 0.829 Seg: 0.9 Link: 0.8\n",
      "P: 0.947 R: 0.738 F: 0.829 Seg: 0.9 Link: 0.7\n",
      "P: 0.947 R: 0.738 F: 0.829 Seg: 0.9 Link: 0.6\n",
      "P: 0.717 R: 0.905 F: 0.8 Seg: 0.7 Link: 0.8\n",
      "P: 0.861 R: 0.738 F: 0.795 Seg: 0.7 Link: 0.4\n",
      "P: 0.871 R: 0.726 F: 0.792 Seg: 0.9 Link: 0.9\n",
      "P: 0.857 R: 0.714 F: 0.779 Seg: 0.6 Link: 0.4\n",
      "P: 0.675 R: 0.917 F: 0.778 Seg: 0.6 Link: 0.7\n",
      "P: 0.674 R: 0.911 F: 0.775 Seg: 0.5 Link: 0.5\n",
      "P: 0.861 R: 0.702 F: 0.774 Seg: 0.8 Link: 0.4\n",
      "P: 0.911 R: 0.667 F: 0.77 Seg: 0.9 Link: 0.4\n",
      "P: 0.63 R: 0.821 F: 0.713 Seg: 0.8 Link: 0.9\n",
      "P: 0.797 R: 0.631 F: 0.704 Seg: 0.7 Link: 0.3\n",
      "P: 0.862 R: 0.595 F: 0.704 Seg: 0.9 Link: 0.3\n",
      "P: 0.794 R: 0.619 F: 0.696 Seg: 0.7 Link: 0.2\n",
      "P: 0.794 R: 0.619 F: 0.696 Seg: 0.7 Link: 0.1\n",
      "P: 0.794 R: 0.619 F: 0.696 Seg: 0.6 Link: 0.3\n",
      "P: 0.798 R: 0.613 F: 0.694 Seg: 0.8 Link: 0.3\n",
      "P: 0.791 R: 0.607 F: 0.687 Seg: 0.6 Link: 0.2\n",
      "P: 0.791 R: 0.607 F: 0.687 Seg: 0.6 Link: 0.1\n",
      "P: 0.795 R: 0.601 F: 0.685 Seg: 0.8 Link: 0.2\n",
      "P: 0.795 R: 0.601 F: 0.685 Seg: 0.8 Link: 0.1\n",
      "P: 0.842 R: 0.571 F: 0.681 Seg: 0.9 Link: 0.2\n",
      "P: 0.842 R: 0.571 F: 0.681 Seg: 0.9 Link: 0.1\n",
      "P: 0.533 R: 0.917 F: 0.674 Seg: 0.6 Link: 0.8\n",
      "P: 0.662 R: 0.607 F: 0.634 Seg: 0.5 Link: 0.4\n",
      "P: 0.488 R: 0.875 F: 0.627 Seg: 0.7 Link: 0.9\n",
      "P: 0.6 R: 0.518 F: 0.556 Seg: 0.5 Link: 0.3\n",
      "P: 0.597 R: 0.512 F: 0.551 Seg: 0.5 Link: 0.2\n",
      "P: 0.597 R: 0.512 F: 0.551 Seg: 0.5 Link: 0.1\n",
      "P: 0.392 R: 0.887 F: 0.544 Seg: 0.6 Link: 0.9\n",
      "P: 0.376 R: 0.946 F: 0.538 Seg: 0.5 Link: 0.6\n",
      "P: 0.318 R: 0.935 F: 0.474 Seg: 0.5 Link: 0.7\n",
      "P: 0.281 R: 0.935 F: 0.433 Seg: 0.5 Link: 0.8\n",
      "P: 0.237 R: 0.917 F: 0.377 Seg: 0.5 Link: 0.9\n",
      "P: 0.045 R: 0.375 F: 0.081 Seg: 0.4 Link: 0.4\n",
      "P: 0.045 R: 0.375 F: 0.081 Seg: 0.3 Link: 0.4\n",
      "P: 0.045 R: 0.375 F: 0.081 Seg: 0.2 Link: 0.4\n",
      "P: 0.045 R: 0.375 F: 0.081 Seg: 0.1 Link: 0.4\n",
      "P: 0.036 R: 0.292 F: 0.064 Seg: 0.4 Link: 0.3\n",
      "P: 0.036 R: 0.292 F: 0.064 Seg: 0.3 Link: 0.3\n",
      "P: 0.036 R: 0.292 F: 0.064 Seg: 0.2 Link: 0.3\n",
      "P: 0.036 R: 0.292 F: 0.064 Seg: 0.1 Link: 0.3\n",
      "P: 0.035 R: 0.286 F: 0.063 Seg: 0.4 Link: 0.2\n",
      "P: 0.035 R: 0.286 F: 0.063 Seg: 0.4 Link: 0.1\n",
      "P: 0.035 R: 0.286 F: 0.063 Seg: 0.3 Link: 0.2\n",
      "P: 0.035 R: 0.286 F: 0.063 Seg: 0.3 Link: 0.1\n",
      "P: 0.035 R: 0.286 F: 0.063 Seg: 0.2 Link: 0.2\n",
      "P: 0.035 R: 0.286 F: 0.063 Seg: 0.2 Link: 0.1\n",
      "P: 0.035 R: 0.286 F: 0.063 Seg: 0.1 Link: 0.2\n",
      "P: 0.035 R: 0.286 F: 0.063 Seg: 0.1 Link: 0.1\n",
      "P: 0.013 R: 0.952 F: 0.026 Seg: 0.4 Link: 0.6\n",
      "P: 0.013 R: 0.952 F: 0.026 Seg: 0.3 Link: 0.6\n",
      "P: 0.013 R: 0.952 F: 0.026 Seg: 0.2 Link: 0.6\n",
      "P: 0.013 R: 0.952 F: 0.026 Seg: 0.1 Link: 0.6\n",
      "P: 0.013 R: 0.917 F: 0.026 Seg: 0.4 Link: 0.5\n",
      "P: 0.013 R: 0.917 F: 0.026 Seg: 0.3 Link: 0.5\n",
      "P: 0.013 R: 0.917 F: 0.026 Seg: 0.2 Link: 0.5\n",
      "P: 0.013 R: 0.917 F: 0.026 Seg: 0.1 Link: 0.5\n",
      "P: 0.013 R: 0.94 F: 0.025 Seg: 0.4 Link: 0.7\n",
      "P: 0.013 R: 0.94 F: 0.025 Seg: 0.3 Link: 0.7\n",
      "P: 0.013 R: 0.94 F: 0.025 Seg: 0.2 Link: 0.7\n",
      "P: 0.013 R: 0.94 F: 0.025 Seg: 0.1 Link: 0.7\n",
      "P: 0.013 R: 0.94 F: 0.025 Seg: 0.4 Link: 0.8\n",
      "P: 0.013 R: 0.94 F: 0.025 Seg: 0.3 Link: 0.8\n",
      "P: 0.013 R: 0.94 F: 0.025 Seg: 0.2 Link: 0.8\n",
      "P: 0.013 R: 0.94 F: 0.025 Seg: 0.1 Link: 0.8\n",
      "P: 0.012 R: 0.923 F: 0.025 Seg: 0.4 Link: 0.9\n",
      "P: 0.012 R: 0.923 F: 0.025 Seg: 0.3 Link: 0.9\n",
      "P: 0.012 R: 0.923 F: 0.025 Seg: 0.2 Link: 0.9\n",
      "P: 0.012 R: 0.923 F: 0.025 Seg: 0.1 Link: 0.9\n"
     ]
    }
   ],
   "source": [
    "from SegLink.sl_metric import evaluate_results, fscore\n",
    "\n",
    "def detection_results(preds, data):\n",
    "    steps_seg = np.arange(0.1, 1, 0.1)\n",
    "    steps_lnk = np.arange(0.1, 1, 0.1)\n",
    "\n",
    "    ordered = []\n",
    "    for i, segment_threshold in enumerate(steps_seg):\n",
    "        for j, link_threshold in enumerate(steps_lnk):\n",
    "            results = [prior_util.decode(p, segment_threshold=segment_threshold, link_threshold=link_threshold) for p in preds]\n",
    "            TP, FP, FN = evaluate_results(data, results)\n",
    "            recall = TP / (TP+FN)\n",
    "            precision = TP / (TP+FP)\n",
    "            fmes = fscore(precision, recall)\n",
    "            ordered.append([fmes, segment_threshold, link_threshold, precision, recall])\n",
    "    ordered.sort(reverse=True)\n",
    "    for i in ordered:\n",
    "        print(\"P:\", round(i[3], 3), \"R:\", round(i[4], 3), \"F:\", round(i[0], 3), \"Seg:\", round(i[1], 2), \"Link:\", round(i[2], 2))\n",
    "        \n",
    "detection_results(preds, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRNN Single Image Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# average = 0\n",
    "# correct = 0\n",
    "# number = len(testing_icdar2015_recognition_image_names)\n",
    "# predictions = []\n",
    "# random.seed(1337)\n",
    "# for j in range(0,200):\n",
    "#     img = testing_icdar2015_recognition_images[j]\n",
    "# #     gt_data = gt[j].lower()\n",
    "#     start = time.time()\n",
    "#     boxes = np.array([[0.0, 0.0, 1.0, 1.0]])\n",
    "#     words = crop_words(img, boxes, 32, width=256, grayscale=True)\n",
    "#     words = np.asarray([w.transpose(1,0,2) for w in words])\n",
    "#     res_crnn = crnn_model.predict(words)\n",
    "#     for i in range(len(res_crnn)):\n",
    "#         chars = [alphabet[c] for c in np.argmax(res_crnn[i], axis=1)]\n",
    "#         res_str = decode(chars)\n",
    "#         end = time.time()\n",
    "#         average = average + (end - start)\n",
    "#         res = escape_latex(res_str).lower()\n",
    "# #         semgmented_words = segment.segment(res)\n",
    "# #         corrected_word = clean.correction(res)\n",
    "# #         print(corrected_word)\n",
    "# #         if len(semgmented_words) == 0:\n",
    "# #             corrected_word = clean.correction(segmented_words[0])\n",
    "#         predictions.append([testing_icdar2015_recognition_image_names[j], res])\n",
    "# #         else:\n",
    "# #             sortedwords = sorted(semgmented_words, key=len)\n",
    "# #             selected_word = sortedwords[-1]\n",
    "# #             predictions.append([testing_icdar2015_recognition_image_names[j], selected_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with open(\"Output_2015.txt\", \"w\") as text_file:\n",
    "#     for i in range(len(predictions)):\n",
    "#         first = predictions[i][0].split(\"/\")[-1].split(\"_\")[-1]\n",
    "#         second = predictions[i][1]\n",
    "#         third = \"\"\n",
    "#         for c in range(len(second)):\n",
    "#             if second[c] == \"\\\\\" or second[c] == \"\\\"\":\n",
    "#                 third = second[:c] + \"\\\\\" + second[c:]\n",
    "#         if len(third) == 0:\n",
    "#             line = first + \", \\\"\" + second + \"\\\"\" + \"\\n\"\n",
    "#         else:\n",
    "#             line = first + \", \\\"\" + third + \"\\\"\" + \"\\n\"\n",
    "#         text_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textfile = open(\"results.csv\", 'r', encoding='utf-8-sig')\n",
    "# textfile_data = textfile.readlines()\n",
    "# textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# correct = 0\n",
    "# num_lines = 0\n",
    "# for i in range(len(textfile_data)):\n",
    "#     line = textfile_data[i].split(\";\")[4:5][0]\n",
    "#     if i != 0:\n",
    "#         num_lines+=1\n",
    "#         if line == \"0\":\n",
    "#             correct+=1\n",
    "# print(correct / num_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(tp, fp):\n",
    "    if tp == 0 and fp == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return tp/(tp+fp)\n",
    "\n",
    "def recall(tp, fn):\n",
    "    if tp == 0 and fn == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return tp/(tp+fn)\n",
    "\n",
    "def fscore(p, r):\n",
    "    if p == 0 and r == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2*p*r/(p+r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End-to-end Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['lines:', 'i', 'lost', 'kevin', 'will', 'line', 'and', 'and', 'the', '(and', 'the', 'out', 'you', \"don't\", 'pkg']\n",
      "PR: ['t', 'and', 'the', 'line', 'out', 'lines:', 'wiltig)', 'the', 'and', 'lost', 'kevin']\n",
      "RW: ['t', 'and', 'the', 'line', 'out', 'lines:', 'wiltig)', 'the', 'and', 'lost', 'kevin']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['i', 'will', '(and', 'you', \"don't\", 'pkg']\n",
      "PR: ['t', 'wiltig)']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 9\n",
      "FP: 2\n",
      "FN: 6\n",
      "PRECISION: 0.8181818181818182\n",
      "RECALL: 0.6\n",
      "FSCORE: 0.6923076923076923\n",
      "ACCURACY: 0.6\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['had', 'our', 'jacket', '>>arno', 'and', '1993', 'the', 'out', 'need', 'any', 'are']\n",
      "PR: ['ut', 'ta', 'and', '993', 'jacket', '>>apne']\n",
      "RW: ['ut', 'ta', 'and', '993', 'jacket', '>>apne']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['had', 'our', '>>arno', '1993', 'the', 'out', 'need', 'any', 'are']\n",
      "PR: ['ut', 'ta', '993', '>>apne']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 2\n",
      "FP: 4\n",
      "FN: 9\n",
      "PRECISION: 0.3333333333333333\n",
      "RECALL: 0.18181818181818182\n",
      "FSCORE: 0.23529411764705885\n",
      "ACCURACY: 0.18181818181818182\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['their', 'from', 'true', 'a', 'new', 'and', 'they', 'vancouver', 'reports', 'new', 'out']\n",
      "PR: ['a', 'and', 'new', '\"ancouver', 'eports']\n",
      "RW: ['a', 'and', 'new', '\"ancouver', 'eports']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['their', 'from', 'true', 'they', 'vancouver', 'reports', 'new', 'out']\n",
      "PR: ['\"ancouver', 'eports']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 3\n",
      "FP: 2\n",
      "FN: 8\n",
      "PRECISION: 0.6\n",
      "RECALL: 0.2727272727272727\n",
      "FSCORE: 0.37499999999999994\n",
      "ACCURACY: 0.2727272727272727\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['driving', 'i', 'live', 'in', 'list', 'the']\n",
      "PR: ['anver', 'the']\n",
      "RW: ['anver', 'the']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['driving', 'i', 'live', 'in', 'list']\n",
      "PR: ['anver']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 1\n",
      "FP: 1\n",
      "FN: 5\n",
      "PRECISION: 0.5\n",
      "RECALL: 0.16666666666666666\n",
      "FSCORE: 0.25\n",
      "ACCURACY: 0.16666666666666666\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['all', 'keep', 'such', 'low', 'much', 'remove', 'more', 'sites', 'zack']\n",
      "PR: ['nore', 'remove', 'mesites', 'facr', 'much']\n",
      "RW: ['nore', 'remove', 'mesites', 'facr', 'much']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['all', 'keep', 'such', 'low', 'more', 'sites', 'zack']\n",
      "PR: ['nore', 'mesites', 'facr']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 2\n",
      "FP: 3\n",
      "FN: 7\n",
      "PRECISION: 0.4\n",
      "RECALL: 0.2222222222222222\n",
      "FSCORE: 0.2857142857142857\n",
      "ACCURACY: 0.2222222222222222\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['lines:', 'hi:', 'yet.', '-', 'such', 'well,', 'it', 'power', 'off', 'uucp:']\n",
      "PR: ['powe', 'off', 'yet.', 'such', 'uucp:', 'wae']\n",
      "RW: ['powe', 'off', 'yet.', 'such', 'uucp:', 'wae']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['lines:', 'hi:', '-', 'well,', 'it', 'power']\n",
      "PR: ['powe', 'wae']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 4\n",
      "FP: 2\n",
      "FN: 6\n",
      "PRECISION: 0.6666666666666666\n",
      "RECALL: 0.4\n",
      "FSCORE: 0.5\n",
      "ACCURACY: 0.4\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['the', 'apr', '93', 'have', 'phoenix', 'thanks', 'can', '>>years', 'the', 'was']\n",
      "PR: ['can', 'the', 'hnthe', 'waugs', 'p>>years']\n",
      "RW: ['can', 'the', 'hnthe', 'waugs', 'p>>years']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['apr', '93', 'have', 'phoenix', 'thanks', '>>years', 'the', 'was']\n",
      "PR: ['hnthe', 'waugs', 'p>>years']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 2\n",
      "FP: 3\n",
      "FN: 8\n",
      "PRECISION: 0.4\n",
      "RECALL: 0.2\n",
      "FSCORE: 0.26666666666666666\n",
      "ACCURACY: 0.2\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['hammers.', 'oooops,', \"don't\", 'have', 'any', ':-)', 'in', 'the', 'safeties', 'betweena', 'glock', 'and', 'the', 'glock', 'as', 'a', 'very', 'high', 'cap', 'some', 'out', 'and']\n",
      "PR: ['out', 'safeties', 'w', 'lackan', 'veryhicn']\n",
      "RW: ['out', 'safeties', 'w', 'lackan', 'veryhicn']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['hammers.', 'oooops,', \"don't\", 'have', 'any', ':-)', 'in', 'the', 'betweena', 'glock', 'and', 'the', 'glock', 'as', 'a', 'very', 'high', 'cap', 'some', 'and']\n",
      "PR: ['w', 'lackan', 'veryhicn']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 2\n",
      "FP: 3\n",
      "FN: 20\n",
      "PRECISION: 0.4\n",
      "RECALL: 0.09090909090909091\n",
      "FSCORE: 0.14814814814814814\n",
      "ACCURACY: 0.09090909090909091\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['and', 'a', 'gm', 'what', 'the', 'for', 'it.']\n",
      "PR: ['fo?', '(t.what', 'the']\n",
      "RW: ['fo?', '(t.what', 'the']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['and', 'a', 'gm', 'what', 'for', 'it.']\n",
      "PR: ['fo?', '(t.what']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 1\n",
      "FP: 2\n",
      "FN: 6\n",
      "PRECISION: 0.3333333333333333\n",
      "RECALL: 0.14285714285714285\n",
      "FSCORE: 0.2\n",
      "ACCURACY: 0.14285714285714285\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['the', 'the', 'nntp-posting-host:', 'ug.cs.dal.ca', 'for', 'comments', 'on', 'not', 'even', 'thank', 'you...']\n",
      "PR: ['nwscement.', 'the']\n",
      "RW: ['nwscement.', 'the']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['the', 'nntp-posting-host:', 'ug.cs.dal.ca', 'for', 'comments', 'on', 'not', 'even', 'thank', 'you...']\n",
      "PR: ['nwscement.']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 1\n",
      "FP: 1\n",
      "FN: 10\n",
      "PRECISION: 0.5\n",
      "RECALL: 0.09090909090909091\n",
      "FSCORE: 0.15384615384615385\n",
      "ACCURACY: 0.09090909090909091\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['you', '2400', 'buad', 'hayes', 'dip', 'switch,', 'the', 'system', 'a', '2400', 'baud', 'hayes', 'external', 'the', 'internal', 'modem', 'the', 'how', 'audio', 'the', 'gb>']\n",
      "PR: ['wich', 'you', 'dip', 'ae', 'rown', 'the']\n",
      "RW: ['wich', 'you', 'dip', 'ae', 'rown', 'the']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['2400', 'buad', 'hayes', 'switch,', 'system', 'a', '2400', 'baud', 'hayes', 'external', 'the', 'internal', 'modem', 'the', 'how', 'audio', 'the', 'gb>']\n",
      "PR: ['wich', 'ae', 'rown']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 3\n",
      "FP: 3\n",
      "FN: 18\n",
      "PRECISION: 0.5\n",
      "RECALL: 0.14285714285714285\n",
      "FSCORE: 0.22222222222222224\n",
      "ACCURACY: 0.14285714285714285\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['_not_', 'make', 'type', '1', 'postscript', 'fonts', 'x11', 'programs.', 'it', 'is', 'not', 'one', 'third-party', 'version', 'which', 'does', 'make', 'available,', 'however)', '>by', 'have', 'from:', '>or', 'say']\n",
      "PR: ['mothita', 'have', 'make', '>by', 'not']\n",
      "RW: ['mothita', 'have', 'make', '>by', 'not']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['_not_', 'type', '1', 'postscript', 'fonts', 'x11', 'programs.', 'it', 'is', 'one', 'third-party', 'version', 'which', 'does', 'make', 'available,', 'however)', 'from:', '>or', 'say']\n",
      "PR: ['mothita']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 4\n",
      "FP: 1\n",
      "FN: 20\n",
      "PRECISION: 0.8\n",
      "RECALL: 0.16666666666666666\n",
      "FSCORE: 0.27586206896551724\n",
      "ACCURACY: 0.16666666666666666\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['26', '0', 'own', 'and', 'tim', 'you', 'you', 'things', 'are', 'shaping']\n",
      "PR: ['sand', 'you', 'own', 'shaping', 'are', 'things']\n",
      "RW: ['sand', 'you', 'own', 'shaping', 'are', 'things']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['26', '0', 'and', 'tim', 'you']\n",
      "PR: ['sand']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 5\n",
      "FP: 1\n",
      "FN: 5\n",
      "PRECISION: 0.8333333333333334\n",
      "RECALL: 0.5\n",
      "FSCORE: 0.625\n",
      "ACCURACY: 0.5\n",
      "\n",
      "=============================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['from', 'club', 'new', 'lines:', 'the', 're:']\n",
      "PR: ['club', 'the', 'from', 'the', 're:', 'lines:']\n",
      "RW: ['club', 'the', 'from', 'the', 're:', 'lines:']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['new']\n",
      "PR: ['the']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 5\n",
      "FP: 1\n",
      "FN: 1\n",
      "PRECISION: 0.8333333333333334\n",
      "RECALL: 0.8333333333333334\n",
      "FSCORE: 0.8333333333333334\n",
      "ACCURACY: 0.8333333333333334\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['also', 'in', 'a', 'thanks', 'any', 'kelly', 'xmol', 'some', 'two', 'inches', 'inches', 'for']\n",
      "PR: ['xmo1', 'in', 'tae', 'thanks', 'a', 'the', 'te', 'two', 'also', 'fo']\n",
      "RW: ['xmo1', 'in', 'tae', 'thanks', 'a', 'the', 'te', 'two', 'also', 'fo']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['any', 'kelly', 'xmol', 'some', 'inches', 'inches', 'for']\n",
      "PR: ['xmo1', 'tae', 'the', 'te', 'fo']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 5\n",
      "FP: 5\n",
      "FN: 7\n",
      "PRECISION: 0.5\n",
      "RECALL: 0.4166666666666667\n",
      "FSCORE: 0.45454545454545453\n",
      "ACCURACY: 0.4166666666666667\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['lines:', 'hello,', \"i'm\", 'the', 'that', 'fine.', 'the', \"i've\", 'like', 'for']\n",
      "PR: ['yi', 'tad', 'like', 'lines:', 'te']\n",
      "RW: ['yi', 'tad', 'like', 'lines:', 'te']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['hello,', \"i'm\", 'the', 'that', 'fine.', 'the', \"i've\", 'for']\n",
      "PR: ['yi', 'tad', 'te']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 2\n",
      "FP: 3\n",
      "FN: 8\n",
      "PRECISION: 0.4\n",
      "RECALL: 0.2\n",
      "FSCORE: 0.26666666666666666\n",
      "ACCURACY: 0.2\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['end', 'xref:', 'from:', 'their', 'organization:', 'keywords:']\n",
      "PR: ['o', 'their', 'end', 'xref:']\n",
      "RW: ['o', 'their', 'end', 'xref:']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['from:', 'organization:', 'keywords:']\n",
      "PR: ['o']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 3\n",
      "FP: 1\n",
      "FN: 3\n",
      "PRECISION: 0.75\n",
      "RECALL: 0.5\n",
      "FSCORE: 0.6\n",
      "ACCURACY: 0.5\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['how', 'size']\n",
      "PR: ['size', 'how']\n",
      "RW: ['size', 'how']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: []\n",
      "PR: []\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 2\n",
      "FP: 0\n",
      "FN: 0\n",
      "PRECISION: 1.0\n",
      "RECALL: 1.0\n",
      "FSCORE: 1.0\n",
      "ACCURACY: 1.0\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['let', '[stuff', 'deleted]', 'from:', '\"paul', 'hager\"', 'on', 'bcci', 'scandal', 'message-id:']\n",
      "PR: ['[stuff', 'mecgran.', '', 'from:', 'on', 'let', 'scandal']\n",
      "RW: ['[stuff', 'mecgran.', '', 'from:', 'on', 'let', 'scandal']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['deleted]', '\"paul', 'hager\"', 'bcci', 'message-id:']\n",
      "PR: ['mecgran.', '']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 5\n",
      "FP: 2\n",
      "FN: 5\n",
      "PRECISION: 0.7142857142857143\n",
      "RECALL: 0.5\n",
      "FSCORE: 0.588235294117647\n",
      "ACCURACY: 0.5\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['message-id:', 'lists', 'the', 'press', 'bye', 'the', 'his', 'hiring', 'a', 'serious', 'file', 'space,', 'but', 'arlow', 'they', 'now']\n",
      "PR: ['space,', 'the', 'bye', 'mesage-id:', 'but', 'arlow', 'the', 'a', 'press', 'pae', 'to']\n",
      "RW: ['space,', 'the', 'bye', 'mesage-id:', 'but', 'arlow', 'the', 'a', 'press', 'pae', 'to']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['message-id:', 'lists', 'his', 'hiring', 'serious', 'file', 'they', 'now']\n",
      "PR: ['mesage-id:', 'pae', 'to']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 8\n",
      "FP: 3\n",
      "FN: 8\n",
      "PRECISION: 0.7272727272727273\n",
      "RECALL: 0.5\n",
      "FSCORE: 0.5925925925925926\n",
      "ACCURACY: 0.5\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['wed,', 'gun', 'owners', 'be', 'a', 'very', 'time', 'this', 'is', 'anyone']\n",
      "PR: ['a', 'wed,', 'sis', 'time', 'gun']\n",
      "RW: ['a', 'wed,', 'sis', 'time', 'gun']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['owners', 'be', 'very', 'this', 'is', 'anyone']\n",
      "PR: ['sis']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 4\n",
      "FP: 1\n",
      "FN: 6\n",
      "PRECISION: 0.8\n",
      "RECALL: 0.4\n",
      "FSCORE: 0.5333333333333333\n",
      "ACCURACY: 0.4\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['apple', '(there', 'should', 'is', 'one', 'for', 'up', 'a', 'got', 'it', 'dumps,', 'the', 'doing', \"that's\", 'what', 'reply', 'are']\n",
      "PR: ['a', 'should', 'got', 'for', 'the', 'are', 'aopre', 'the', 'yorg', 'toe', 'is', 'one']\n",
      "RW: ['a', 'should', 'got', 'for', 'the', 'are', 'aopre', 'the', 'yorg', 'toe', 'is', 'one']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['apple', '(there', 'up', 'it', 'dumps,', 'doing', \"that's\", 'what', 'reply']\n",
      "PR: ['aopre', 'the', 'yorg', 'toe']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 8\n",
      "FP: 4\n",
      "FN: 9\n",
      "PRECISION: 0.6666666666666666\n",
      "RECALL: 0.47058823529411764\n",
      "FSCORE: 0.5517241379310345\n",
      "ACCURACY: 0.47058823529411764\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['while,', 'alex', 'i', 'am', 'date:', 'lines:', 'for', 'the']\n",
      "PR: ['while,', 'am', 'toe', 'an', 'bxx', 'to', 'a']\n",
      "RW: ['while,', 'am', 'toe', 'an', 'bxx', 'to', 'a']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['alex', 'i', 'date:', 'lines:', 'for', 'the']\n",
      "PR: ['toe', 'an', 'bxx', 'to', 'a']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 2\n",
      "FP: 5\n",
      "FN: 6\n",
      "PRECISION: 0.2857142857142857\n",
      "RECALL: 0.25\n",
      "FSCORE: 0.26666666666666666\n",
      "ACCURACY: 0.25\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['with', \"can't\", 'yours', 'the', 'file:', 'expect', 'road,', 'kit']\n",
      "PR: ['kits', 'expect', 't', 'file:', 'ith']\n",
      "RW: ['kits', 'expect', 't', 'file:', 'ith']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['with', \"can't\", 'yours', 'the', 'road,', 'kit']\n",
      "PR: ['kits', 't', 'ith']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 2\n",
      "FP: 3\n",
      "FN: 6\n",
      "PRECISION: 0.4\n",
      "RECALL: 0.25\n",
      "FSCORE: 0.3076923076923077\n",
      "ACCURACY: 0.25\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['the', 'the', 'for', 'me>', 'but', 'there']\n",
      "PR: ['there', 'me>', 'the', 'but', 'the', 'a']\n",
      "RW: ['there', 'me>', 'the', 'but', 'the', 'a']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['for']\n",
      "PR: ['a']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 5\n",
      "FP: 1\n",
      "FN: 1\n",
      "PRECISION: 0.8333333333333334\n",
      "RECALL: 0.8333333333333334\n",
      "FSCORE: 0.8333333333333334\n",
      "ACCURACY: 0.8333333333333334\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['to', 'the', 'and', 'or', 'the', 'penny\"', 'from', 'that']\n",
      "PR: ['to', 'that', 'the', 'the', 'or', 'from', 'peny', 'and']\n",
      "RW: ['to', 'that', 'the', 'the', 'or', 'from', 'peny', 'and']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['penny\"']\n",
      "PR: ['peny']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 7\n",
      "FP: 1\n",
      "FN: 1\n",
      "PRECISION: 0.875\n",
      "RECALL: 0.875\n",
      "FSCORE: 0.875\n",
      "ACCURACY: 0.875\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['they', 'are', 'work,', 'will', 'be', 'available.', '1.', 'regular', '2.', 'short', '3.', 'video', 'attend', 'the', 'seminar)', 'predictions', 'message-id:', 'sender:']\n",
      "PR: ['>-short', 'attend', 'available.', 'the', 'are', 'seminar)', 'worhy', 'merronin.', 'they', 'will']\n",
      "RW: ['>-short', 'attend', 'available.', 'the', 'are', 'seminar)', 'worhy', 'merronin.', 'they', 'will']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['work,', 'be', '1.', 'regular', '2.', 'short', '3.', 'video', 'predictions', 'message-id:', 'sender:']\n",
      "PR: ['>-short', 'worhy', 'merronin.']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 7\n",
      "FP: 3\n",
      "FN: 11\n",
      "PRECISION: 0.7\n",
      "RECALL: 0.3888888888888889\n",
      "FSCORE: 0.5\n",
      "ACCURACY: 0.3888888888888889\n",
      "\n",
      "=============================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['twm', 'one', 'the', 'bet', 'the', 'rate', 'project', 'is', 'own']\n",
      "PR: ['bet', 'own', 'one', 'rate', 'twm']\n",
      "RW: ['bet', 'own', 'one', 'rate', 'twm']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['the', 'the', 'project', 'is']\n",
      "PR: []\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 5\n",
      "FP: 0\n",
      "FN: 4\n",
      "PRECISION: 1.0\n",
      "RECALL: 0.5555555555555556\n",
      "FSCORE: 0.7142857142857143\n",
      "ACCURACY: 0.5555555555555556\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['(the', 'that', 'the', 'pll', 'apr', 'lot', 'a', 'small', 'available', 'soon', 'muslims', 'vicious', 'and', 'how', 'will', 'work']\n",
      "PR: ['soon', 'ae', 'a', 'available', 'smdl', 'wort', 'a', 'muslims', 'and', 'how', 'the', 'lot', 'that', 'vicious', 'por', 'will']\n",
      "RW: ['soon', 'ae', 'a', 'available', 'smdl', 'wort', 'a', 'muslims', 'and', 'how', 'the', 'lot', 'that', 'vicious', 'por', 'will']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['(the', 'pll', 'apr', 'small', 'work']\n",
      "PR: ['ae', 'smdl', 'wort', 'a', 'por']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 11\n",
      "FP: 5\n",
      "FN: 5\n",
      "PRECISION: 0.6875\n",
      "RECALL: 0.6875\n",
      "FSCORE: 0.6875\n",
      "ACCURACY: 0.6875\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['here', 'rob', 're:', 'to', 'those', '$450', 'and', '25mhz', 'the', 'speed', 'are', 'the', 'applied', 'anyone', 'had', 'may', 'even', 'thanks', 'craig', 'and', 'and']\n",
      "PR: ['those', 'and', 'and', 'are', 'the', 'to', 'the', 'and', 'craige', 'the', 'had', 'i', 'speed', 'may', 'here', 'sche', 'even']\n",
      "RW: ['those', 'and', 'and', 'are', 'the', 'to', 'the', 'and', 'craige', 'the', 'had', 'i', 'speed', 'may', 'here', 'sche', 'even']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['rob', 're:', '$450', '25mhz', 'applied', 'anyone', 'thanks', 'craig']\n",
      "PR: ['craige', 'the', 'i', 'sche']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 13\n",
      "FP: 4\n",
      "FN: 8\n",
      "PRECISION: 0.7647058823529411\n",
      "RECALL: 0.6190476190476191\n",
      "FSCORE: 0.6842105263157895\n",
      "ACCURACY: 0.6190476190476191\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['apr', 'so', 'i', 'was', 'hit', 'would', 'tagged', 'on', 'their', 'price', 'the', 'from:', 'the', 'dark', 'even', 'when', 'it', 'you', 'exact', '150', 'subject:', 're:', 'organization:', '26', 'apr']\n",
      "PR: ['tagg', 'the', 'stoud', '150', 'you', 'on', 'even', 'the', 'exact', 're:', 'wll', 'price', 'when', 'toe', 'apr']\n",
      "RW: ['tagg', 'the', 'stoud', '150', 'you', 'on', 'even', 'the', 'exact', 're:', 'wll', 'price', 'when', 'toe', 'apr']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['so', 'i', 'was', 'hit', 'would', 'tagged', 'their', 'from:', 'dark', 'it', 'subject:', 'organization:', '26', 'apr']\n",
      "PR: ['tagg', 'stoud', 'wll', 'toe']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 11\n",
      "FP: 4\n",
      "FN: 14\n",
      "PRECISION: 0.7333333333333333\n",
      "RECALL: 0.44\n",
      "FSCORE: 0.5499999999999999\n",
      "ACCURACY: 0.44\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['from:', 're:', 'log', 'your', 'note', 'that', 'your', 'karl', 'are', 'at', 'are', 'at', 'plus', 'christine', 'chan', 'new', 'the', 'back']\n",
      "PR: ['log', 'note', 'toe', 'at', 'your', 'that', 'the', 'are', 'are', 'new', 'from:', 'chan', 'at', 'karl', 'christine']\n",
      "RW: ['log', 'note', 'toe', 'at', 'your', 'that', 'the', 'are', 'are', 'new', 'from:', 'chan', 'at', 'karl', 'christine']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['re:', 'your', 'plus', 'back']\n",
      "PR: ['toe']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 14\n",
      "FP: 1\n",
      "FN: 4\n",
      "PRECISION: 0.9333333333333333\n",
      "RECALL: 0.7777777777777778\n",
      "FSCORE: 0.8484848484848485\n",
      "ACCURACY: 0.7777777777777778\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['and', 'laser', 'care', 'believe', 'it', 'about', 'half']\n",
      "PR: ['and', 'deneven', 'laser']\n",
      "RW: ['and', 'deneven', 'laser']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['care', 'believe', 'it', 'about', 'half']\n",
      "PR: ['deneven']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 2\n",
      "FP: 1\n",
      "FN: 5\n",
      "PRECISION: 0.6666666666666666\n",
      "RECALL: 0.2857142857142857\n",
      "FSCORE: 0.4\n",
      "ACCURACY: 0.2857142857142857\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['lines:', '29', 'month', 'old', 'tape', 'deck,', 'cryptosystem', 'practice?', 'many', 'people', 'would', 'but', 'you', 'few', 'seen', 'than', 'more', 'way', 'the', 'the', 'all', 'are', 'are', '(or', 'lines:', 'dear']\n",
      "PR: ['lines', 'mor', '(or', 'han', 'few', '29', 'woulkd', 'many', 'all', 'way', 'mo', 'are', 'are', 'old', 'n:', 'een', 'deck.', 'people', 'tape', 'ta']\n",
      "RW: ['lines', 'mor', '(or', 'han', 'few', '29', 'woulkd', 'many', 'all', 'way', 'mo', 'are', 'are', 'old', 'n:', 'een', 'deck.', 'people', 'tape', 'ta']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['lines:', 'month', 'deck,', 'cryptosystem', 'practice?', 'would', 'but', 'you', 'seen', 'than', 'more', 'the', 'the', 'lines:', 'dear']\n",
      "PR: ['lines', 'mor', 'han', 'woulkd', 'mo', 'n:', 'een', 'deck.', 'ta']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 11\n",
      "FP: 9\n",
      "FN: 15\n",
      "PRECISION: 0.55\n",
      "RECALL: 0.4230769230769231\n",
      "FSCORE: 0.47826086956521735\n",
      "ACCURACY: 0.4230769230769231\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['these', 'him', 'see']\n",
      "PR: ['see', 'rethese']\n",
      "RW: ['see', 'rethese']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['these', 'him']\n",
      "PR: ['rethese']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 1\n",
      "FP: 1\n",
      "FN: 2\n",
      "PRECISION: 0.5\n",
      "RECALL: 0.3333333333333333\n",
      "FSCORE: 0.4\n",
      "ACCURACY: 0.3333333333333333\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['course', 'i', 'guess', 'your', 'power', 'brakes,', 'key', 'have', 'we']\n",
      "PR: ['co', 'irse', 'keyver', 'have', 'rakes,', 'we', 'to']\n",
      "RW: ['co', 'irse', 'keyver', 'have', 'rakes,', 'we', 'to']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['course', 'i', 'guess', 'your', 'power', 'brakes,', 'key']\n",
      "PR: ['co', 'irse', 'keyver', 'rakes,', 'to']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 2\n",
      "FP: 5\n",
      "FN: 7\n",
      "PRECISION: 0.2857142857142857\n",
      "RECALL: 0.2222222222222222\n",
      "FSCORE: 0.25\n",
      "ACCURACY: 0.2222222222222222\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['10)', 'lines:', 'to', '\"most\"', 'a', '250']\n",
      "PR: ['ta', '10)']\n",
      "RW: ['ta', '10)']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['lines:', 'to', '\"most\"', 'a', '250']\n",
      "PR: ['ta']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 1\n",
      "FP: 1\n",
      "FN: 5\n",
      "PRECISION: 0.5\n",
      "RECALL: 0.16666666666666666\n",
      "FSCORE: 0.25\n",
      "ACCURACY: 0.16666666666666666\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['the', 'here', 'arm', 'his', 'from:', 'is', 'dale']\n",
      "PR: ['fro', 'arm', 'here', 'his', 'is', 'dale', 'the']\n",
      "RW: ['fro', 'arm', 'here', 'his', 'is', 'dale', 'the']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['from:']\n",
      "PR: ['fro']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 6\n",
      "FP: 1\n",
      "FN: 1\n",
      "PRECISION: 0.8571428571428571\n",
      "RECALL: 0.8571428571428571\n",
      "FSCORE: 0.8571428571428571\n",
      "ACCURACY: 0.8571428571428571\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['to', 'me', 'be', 'nice.']\n",
      "PR: ['one']\n",
      "RW: ['one']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['to', 'me', 'be', 'nice.']\n",
      "PR: ['one']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 0\n",
      "FP: 1\n",
      "FN: 4\n",
      "PRECISION: 0.0\n",
      "RECALL: 0.0\n",
      "FSCORE: 0\n",
      "ACCURACY: 0.0\n",
      "\n",
      "=============================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['would', 'be', 'a', 'one', '>what', 'you', 'support.', \"i've\", 'received', 'would', 'the', 'i', 'use']\n",
      "PR: ['subport', '\"', 'the', 'you', 'a', 'one', 'vo.', \"i've\", 'would', 'i', 'be']\n",
      "RW: ['subport', '\"', 'the', 'you', 'a', 'one', 'vo.', \"i've\", 'would', 'i', 'be']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['>what', 'support.', 'received', 'would', 'use']\n",
      "PR: ['subport', '\"', 'vo.']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 8\n",
      "FP: 3\n",
      "FN: 5\n",
      "PRECISION: 0.7272727272727273\n",
      "RECALL: 0.6153846153846154\n",
      "FSCORE: 0.6666666666666667\n",
      "ACCURACY: 0.6153846153846154\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['and', 'help', \"i've\", 're:', 'will', 'right', 'who', 'bryan', 'from:']\n",
      "PR: ['fom', 'and', 'who', 're:', 'toe', 'help', \"i've\"]\n",
      "RW: ['fom', 'and', 'who', 're:', 'toe', 'help', \"i've\"]\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['will', 'right', 'bryan', 'from:']\n",
      "PR: ['fom', 'toe']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 5\n",
      "FP: 2\n",
      "FN: 4\n",
      "PRECISION: 0.7142857142857143\n",
      "RECALL: 0.5555555555555556\n",
      "FSCORE: 0.6250000000000001\n",
      "ACCURACY: 0.5555555555555556\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['and', 'and', 'geo:', 'gds:', 'for', 'problem', 'and', 'from', 'the', 'one', 'for', 'net', 'two']\n",
      "PR: ['fe', 'the', 'cds.', '>for', 'and', 'one', 'and', 'two', 'f', 'net', 'ceo:']\n",
      "RW: ['fe', 'the', 'cds.', '>for', 'and', 'one', 'and', 'two', 'f', 'net', 'ceo:']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['geo:', 'gds:', 'for', 'problem', 'and', 'from', 'for']\n",
      "PR: ['fe', 'cds.', '>for', 'f', 'ceo:']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 6\n",
      "FP: 5\n",
      "FN: 7\n",
      "PRECISION: 0.5454545454545454\n",
      "RECALL: 0.46153846153846156\n",
      "FSCORE: 0.4999999999999999\n",
      "ACCURACY: 0.46153846153846156\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['jef', 'jef', '\"an', 'the', 'and', 'bit', 'from:', 'for', 'the', 'and', 'the', 'the', 'sort', 'did']\n",
      "PR: ['sorte', 'and', 'tod', 'the', 'the', 'thene', '\"an', 'bit', 'for', 'and']\n",
      "RW: ['sorte', 'and', 'tod', 'the', 'the', 'thene', '\"an', 'bit', 'for', 'and']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['jef', 'jef', 'from:', 'the', 'the', 'sort', 'did']\n",
      "PR: ['sorte', 'tod', 'thene']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 7\n",
      "FP: 3\n",
      "FN: 7\n",
      "PRECISION: 0.7\n",
      "RECALL: 0.5\n",
      "FSCORE: 0.5833333333333334\n",
      "ACCURACY: 0.5\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['that', 'fbi.', 'gut.', 'now', 'the', 'one', 'may', 'that', 'ped', 'said', 'she']\n",
      "PR: ['out', 'e', 'ol', 'te', 'that']\n",
      "RW: ['out', 'e', 'ol', 'te', 'that']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['fbi.', 'gut.', 'now', 'the', 'one', 'may', 'that', 'ped', 'said', 'she']\n",
      "PR: ['out', 'e', 'ol', 'te']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 1\n",
      "FP: 4\n",
      "FN: 10\n",
      "PRECISION: 0.2\n",
      "RECALL: 0.09090909090909091\n",
      "FSCORE: 0.12500000000000003\n",
      "ACCURACY: 0.09090909090909091\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['ago', 'job', 'only', 'much']\n",
      "PR: ['te', 'og', 'job']\n",
      "RW: ['te', 'og', 'job']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['ago', 'only', 'much']\n",
      "PR: ['te', 'og']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 1\n",
      "FP: 2\n",
      "FN: 3\n",
      "PRECISION: 0.3333333333333333\n",
      "RECALL: 0.25\n",
      "FSCORE: 0.28571428571428575\n",
      "ACCURACY: 0.25\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['date:', 'lines:', 'good', 'from:', 'color', 'are']\n",
      "PR: ['are', 'fro', 'good', 'lines:']\n",
      "RW: ['are', 'fro', 'good', 'lines:']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['date:', 'from:', 'color']\n",
      "PR: ['fro']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 3\n",
      "FP: 1\n",
      "FN: 3\n",
      "PRECISION: 0.75\n",
      "RECALL: 0.5\n",
      "FSCORE: 0.6\n",
      "ACCURACY: 0.5\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['oct', 'lines:', 'the', 'is', 'the', 'the', 'fix', 'use', 'put', 'the', 'law', 'but', 'i', 'not', 'you', 'me,', 'you', 'and', '15,', 'and']\n",
      "PR: ['you', 'you', 'is', 'the', 'but', 'and', 'i', 'fix', 'the', 'lines:', 'put', 'use', 'aw)', 'oct']\n",
      "RW: ['you', 'you', 'is', 'the', 'but', 'and', 'i', 'fix', 'the', 'lines:', 'put', 'use', 'aw)', 'oct']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['the', 'the', 'law', 'not', 'me,', '15,', 'and']\n",
      "PR: ['aw)']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 13\n",
      "FP: 1\n",
      "FN: 7\n",
      "PRECISION: 0.9285714285714286\n",
      "RECALL: 0.65\n",
      "FSCORE: 0.7647058823529412\n",
      "ACCURACY: 0.65\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['some', 'vi.', 'easier', 'use.', 'for', 'access', 'news', 'while', 'they', 'maple']\n",
      "PR: ['alcess', 'news', 'easier', 'f', 'they', 'wople', 'some']\n",
      "RW: ['alcess', 'news', 'easier', 'f', 'they', 'wople', 'some']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['vi.', 'use.', 'for', 'access', 'while', 'maple']\n",
      "PR: ['alcess', 'f', 'wople']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 4\n",
      "FP: 3\n",
      "FN: 6\n",
      "PRECISION: 0.5714285714285714\n",
      "RECALL: 0.4\n",
      "FSCORE: 0.47058823529411764\n",
      "ACCURACY: 0.4\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['hi,', 'ms.', 'who', 're:', '>out', 'base', 're:', 'no.', 'few', \"let's\", 'control', 'a']\n",
      "PR: ['>no:', 'who', 'few', 'control']\n",
      "RW: ['>no:', 'who', 'few', 'control']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['hi,', 'ms.', 're:', '>out', 'base', 're:', 'no.', \"let's\", 'a']\n",
      "PR: ['>no:']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 3\n",
      "FP: 1\n",
      "FN: 9\n",
      "PRECISION: 0.75\n",
      "RECALL: 0.25\n",
      "FSCORE: 0.375\n",
      "ACCURACY: 0.25\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['lines:', 'dos.', 'and', 'you', 'party', '-', 'jim', 'are', 'the', 'from:']\n",
      "PR: ['are', 'parth', 'dos.', 'the', 'jim,', 'lines:']\n",
      "RW: ['are', 'parth', 'dos.', 'the', 'jim,', 'lines:']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['and', 'you', 'party', '-', 'jim', 'from:']\n",
      "PR: ['parth', 'jim,']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 4\n",
      "FP: 2\n",
      "FN: 6\n",
      "PRECISION: 0.6666666666666666\n",
      "RECALL: 0.4\n",
      "FSCORE: 0.5\n",
      "ACCURACY: 0.4\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['out', 'standing', 'which', 'unit', 'agrees', 'would']\n",
      "PR: ['which', 'agrees', 'standin', 'would', 'unit']\n",
      "RW: ['which', 'agrees', 'standin', 'would', 'unit']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['out', 'standing']\n",
      "PR: ['standin']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 4\n",
      "FP: 1\n",
      "FN: 2\n",
      "PRECISION: 0.8\n",
      "RECALL: 0.6666666666666666\n",
      "FSCORE: 0.7272727272727272\n",
      "ACCURACY: 0.6666666666666666\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['newly', 'that', '(or', 'get', 'is', 'unlikely', 'that', 'leas', 'can', 'without', 'a/ux']\n",
      "PR: ['unlikely', 'that', 'that', 'wur', 'leas', '']\n",
      "RW: ['unlikely', 'that', 'that', 'wur', 'leas', '']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['newly', '(or', 'get', 'is', 'can', 'without', 'a/ux']\n",
      "PR: ['wur', '']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 4\n",
      "FP: 2\n",
      "FN: 7\n",
      "PRECISION: 0.6666666666666666\n",
      "RECALL: 0.36363636363636365\n",
      "FSCORE: 0.4705882352941177\n",
      "ACCURACY: 0.36363636363636365\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['us', 'base', 'nea', 'as', 'high', 'onto', 'balcony,', \"i've\", 'up', 'in', 'run', 'the', 'thanks!', 'for', 'a']\n",
      "PR: [\"i've\", 'as', 'onto', 'a', 'for/a']\n",
      "RW: [\"i've\", 'as', 'onto', 'a', 'for/a']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['us', 'base', 'nea', 'high', 'balcony,', 'up', 'in', 'run', 'the', 'thanks!', 'for']\n",
      "PR: ['for/a']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 4\n",
      "FP: 1\n",
      "FN: 11\n",
      "PRECISION: 0.8\n",
      "RECALL: 0.26666666666666666\n",
      "FSCORE: 0.4\n",
      "ACCURACY: 0.26666666666666666\n",
      "\n",
      "=============================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: [\"i'm\", 'the', 'this', 'message-id:', 'the', 'don', 'not', 'apr']\n",
      "PR: ['message-id:', 'the', 'this', 'don', \"i'm\"]\n",
      "RW: ['message-id:', 'the', 'this', 'don', \"i'm\"]\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['the', 'not', 'apr']\n",
      "PR: []\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 5\n",
      "FP: 0\n",
      "FN: 3\n",
      "PRECISION: 1.0\n",
      "RECALL: 0.625\n",
      "FSCORE: 0.7692307692307693\n",
      "ACCURACY: 0.625\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['after', 'disk', 'o', 'long']\n",
      "PR: ['disk', 'after']\n",
      "RW: ['disk', 'after']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['o', 'long']\n",
      "PR: []\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 2\n",
      "FP: 0\n",
      "FN: 2\n",
      "PRECISION: 1.0\n",
      "RECALL: 0.5\n",
      "FSCORE: 0.6666666666666666\n",
      "ACCURACY: 0.5\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['the', 'it', 'cost', 'to', 'did', 'it', 'cost', '1)', 'your', 'other']\n",
      "PR: ['sre', 'teve']\n",
      "RW: ['sre', 'teve']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['the', 'it', 'cost', 'to', 'did', 'it', 'cost', '1)', 'your', 'other']\n",
      "PR: ['sre', 'teve']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 0\n",
      "FP: 2\n",
      "FN: 10\n",
      "PRECISION: 0.0\n",
      "RECALL: 0.0\n",
      "FSCORE: 0\n",
      "ACCURACY: 0.0\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['lines:', 'but', 'i']\n",
      "PR: ['yu']\n",
      "RW: ['yu']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['lines:', 'but', 'i']\n",
      "PR: ['yu']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 0\n",
      "FP: 1\n",
      "FN: 3\n",
      "PRECISION: 0.0\n",
      "RECALL: 0.0\n",
      "FSCORE: 0\n",
      "ACCURACY: 0.0\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['>or', 'you', 'but', \"i'm\"]\n",
      "PR: ['but>..', 'imyou']\n",
      "RW: ['but>..', 'imyou']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['>or', 'you', 'but', \"i'm\"]\n",
      "PR: ['but>..', 'imyou']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 0\n",
      "FP: 2\n",
      "FN: 4\n",
      "PRECISION: 0.0\n",
      "RECALL: 0.0\n",
      "FSCORE: 0\n",
      "ACCURACY: 0.0\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['this', 'the', 'your']\n",
      "PR: []\n",
      "RW: []\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['this', 'the', 'your']\n",
      "PR: []\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 0\n",
      "FP: 0\n",
      "FN: 3\n",
      "PRECISION: 0\n",
      "RECALL: 0.0\n",
      "FSCORE: 0\n",
      "ACCURACY: 0.0\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['5', 'for', '5', 'lines:', '11', 'message-id:', 'the']\n",
      "PR: ['lines:', 'message-id:']\n",
      "RW: ['lines:', 'message-id:']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['5', 'for', '5', '11', 'the']\n",
      "PR: []\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 2\n",
      "FP: 0\n",
      "FN: 5\n",
      "PRECISION: 1.0\n",
      "RECALL: 0.2857142857142857\n",
      "FSCORE: 0.4444444444444445\n",
      "ACCURACY: 0.2857142857142857\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['only', 'would', 'the', 'dared', 'talk']\n",
      "PR: ['would', 'talk']\n",
      "RW: ['would', 'talk']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['only', 'the', 'dared']\n",
      "PR: []\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 2\n",
      "FP: 0\n",
      "FN: 3\n",
      "PRECISION: 1.0\n",
      "RECALL: 0.4\n",
      "FSCORE: 0.5714285714285715\n",
      "ACCURACY: 0.4\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: [\"i'm\", 'law', 'is', 'has', 'get', 'these', 'games', 'the']\n",
      "PR: ['games', 'the', 'the']\n",
      "RW: ['games', 'the', 'the']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: [\"i'm\", 'law', 'is', 'has', 'get', 'these']\n",
      "PR: ['the']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 2\n",
      "FP: 1\n",
      "FN: 6\n",
      "PRECISION: 0.6666666666666666\n",
      "RECALL: 0.25\n",
      "FSCORE: 0.36363636363636365\n",
      "ACCURACY: 0.25\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['ever', 'image', 'seen', 'author', 'the', 'can', '400', 'fri,']\n",
      "PR: ['ever', 'image', 'the', '400', 'seen', 'author']\n",
      "RW: ['ever', 'image', 'the', '400', 'seen', 'author']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['can', 'fri,']\n",
      "PR: []\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 6\n",
      "FP: 0\n",
      "FN: 2\n",
      "PRECISION: 1.0\n",
      "RECALL: 0.75\n",
      "FSCORE: 0.8571428571428571\n",
      "ACCURACY: 0.75\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['and', 'from:', '3.1', 'the', 'more', 'bar', 'fund', 'gmt']\n",
      "PR: ['gmt', 'und', 'bar', 'and', 'more', 'from:']\n",
      "RW: ['gmt', 'und', 'bar', 'and', 'more', 'from:']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['3.1', 'the', 'fund']\n",
      "PR: ['und']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 5\n",
      "FP: 1\n",
      "FN: 3\n",
      "PRECISION: 0.8333333333333334\n",
      "RECALL: 0.625\n",
      "FSCORE: 0.7142857142857143\n",
      "ACCURACY: 0.625\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['snf', 'bdf', 'for', 'vii)', 'bsd', '21.', 'them']\n",
      "PR: ['mee', 'snf', 'bdf', '21.']\n",
      "RW: ['mee', 'snf', 'bdf', '21.']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['for', 'vii)', 'bsd', 'them']\n",
      "PR: ['mee']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 3\n",
      "FP: 1\n",
      "FN: 4\n",
      "PRECISION: 0.75\n",
      "RECALL: 0.42857142857142855\n",
      "FSCORE: 0.5454545454545454\n",
      "ACCURACY: 0.42857142857142855\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['buf,', 'remote', 'work', 'need', 'a', \"you'll\", 'from:', 'kit', 'bag', 'cord', '>eliot', 'have', 'a']\n",
      "PR: ['have', 'a', 'vte', 'remote', 'n', 'ldit', 'buet', 'work', 'bag', 'cord']\n",
      "RW: ['have', 'a', 'vte', 'remote', 'n', 'ldit', 'buet', 'work', 'bag', 'cord']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['buf,', 'need', \"you'll\", 'from:', 'kit', '>eliot', 'a']\n",
      "PR: ['vte', 'n', 'ldit', 'buet']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 6\n",
      "FP: 4\n",
      "FN: 7\n",
      "PRECISION: 0.6\n",
      "RECALL: 0.46153846153846156\n",
      "FSCORE: 0.5217391304347826\n",
      "ACCURACY: 0.46153846153846156\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "++++++++++++ BEFORE +++++++++++++\n",
      "GT: ['into', 'count', 'the', 'ad,', 'did', 'signs', 'they', 'used', 'oxidases).', 'for', \"i'm\", 'cmcs', 'people', '(or']\n",
      "PR: ['used', 'for', 'nt', 'people', 'tae', 'they', 'did', '', 'into']\n",
      "RW: ['used', 'for', 'nt', 'people', 'tae', 'they', 'did', '', 'into']\n",
      "\n",
      "++++++++++++ AFTER +++++++++++++\n",
      "GT: ['count', 'the', 'ad,', 'signs', 'oxidases).', \"i'm\", 'cmcs', '(or']\n",
      "PR: ['nt', 'tae', '']\n",
      "RW: []\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "TP: 6\n",
      "FP: 3\n",
      "FN: 8\n",
      "PRECISION: 0.6666666666666666\n",
      "RECALL: 0.42857142857142855\n",
      "FSCORE: 0.5217391304347826\n",
      "ACCURACY: 0.42857142857142855\n",
      "\n",
      "=============================================================================\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-528fc01d0686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mimages_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1798\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1800\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from CRNN.crnn_data import crop_words\n",
    "from CRNN.crnn_utils import decode\n",
    "from SegLink.sl_utils import rbox_to_polygon, polygon_to_rbox\n",
    "from SegLink.ssd_viz import plot_box, escape_latex\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "from skimage.transform import resize as rs\n",
    "\n",
    "def visualize_bounding_box(image, labels):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    for b in labels.tolist():\n",
    "        points = [[float(b[0]), float(b[1])], [float(b[2]), float(b[3])], [float(b[4]), float(b[5])], [float(b[6]), float(b[7])]]\n",
    "        bb = patches.Polygon(points, alpha=0.3, linewidth=2, edgecolor='r', facecolor='b')\n",
    "        ax.add_patch(bb)\n",
    "    plt.show()\n",
    "    \n",
    "# boxes = np.copy(gtu.data[k][:,:-gtu.num_classes])\n",
    "# texts = np.copy(gtu.text[k])    \n",
    "# words = crop_words(img, boxes, input_height, width=input_width, grayscale=True)\n",
    "# words = np.asarray([w.transpose(1,0,2) for w in words])\n",
    "\n",
    "# gts = glob.glob(\"./data/icdar_2013_focused_scene_text/localization/testing/gt/*.txt\")\n",
    "inputs = []\n",
    "images = []\n",
    "images_orig = []\n",
    "data = []\n",
    "counter = 0\n",
    "gtu = gt_util_synth\n",
    "total_correct = 0\n",
    "total_imgs = 0\n",
    "total_text = 0\n",
    "total_time = 0\n",
    "total_accuracy = 0\n",
    "\n",
    "total_p = 0\n",
    "total_r = 0\n",
    "total_f = 0\n",
    "\n",
    "total_tp = 0\n",
    "total_tn = 0\n",
    "total_fp = 0\n",
    "total_fn = 0\n",
    "for i in range(0, gtu.num_samples, 16):\n",
    "    img = cv2.imread(os.path.join(gtu.image_path, gtu.image_names[i]))\n",
    "    images_orig.append(np.copy(img)) \n",
    "    start = time.time()\n",
    "    preds = model.predict(np.asarray([preprocess(img, image_size)]), batch_size=1, verbose=1)\n",
    "    h, w = image_size\n",
    "    img = cv2.resize(img, (w,h), cv2.INTER_LINEAR).astype('float32')\n",
    "    img = img[:, :, (2,1,0)]\n",
    "    img /= 255\n",
    "    images.append(img)\n",
    "    boxes = gtu.data[i]\n",
    "    data.append(boxes)\n",
    "    img2 = img.copy()\n",
    "    \n",
    "    texts = np.copy(gtu.text[i]).tolist()\n",
    "    res = prior_util.decode(preds[0], segment_threshold=0.6, link_threshold=0.3)\n",
    "    img = images_orig[-1]\n",
    "    rboxes = res[:,:5]\n",
    "    if len(rboxes) == 0:\n",
    "        continue\n",
    "        \n",
    "    # ADD A SMALL PADDING TO THE DETECTED BOXES BEFORE RECOGNITION\n",
    "    bh = rboxes[:,3]\n",
    "    rboxes[:,2] += bh * 0.1\n",
    "    rboxes[:,3] += bh * 0.2\n",
    "    \n",
    "    boxes = np.asarray([rbox_to_polygon(r) for r in rboxes])\n",
    "    boxes = np.flip(boxes, axis=1)\n",
    "    boxes = np.reshape(boxes, (-1, 8))\n",
    "\n",
    "    boxes_mask_a = np.array([b[2] > b[3] for b in rboxes]) # width > height, in square world\n",
    "    boxes_mask_b = np.array([not (np.any(b < 0) or np.any(b > 512)) for b in boxes]) # box inside image\n",
    "    boxes_mask = np.logical_and(boxes_mask_a, boxes_mask_b)\n",
    "\n",
    "    boxes = boxes[boxes_mask]\n",
    "    rboxes = rboxes[boxes_mask]\n",
    "\n",
    "    if len(boxes) == 0:\n",
    "        boxes = np.empty((0,8))\n",
    "                \n",
    "    for box in boxes:\n",
    "        for j in range(len(box)):\n",
    "            if j % 2 == 0:\n",
    "                box[j] = box[j]/512\n",
    "            else:\n",
    "                box[j] = box[j]/512\n",
    "    words = crop_words(img, boxes, input_height, width=input_width, grayscale=True)\n",
    "    words = np.asarray([w.transpose(1,0,2) for w in words])\n",
    "\n",
    "    if len(words) > 0:\n",
    "        res_crnn = crnn_model.predict(words)\n",
    "    else:\n",
    "        res_crnn = []\n",
    "    segmented_words = []\n",
    "    raw_preds = []\n",
    "    for k in range(len(res_crnn)):\n",
    "        chars = [alphabet[c] for c in np.argmax(res_crnn[k], axis=1)]        \n",
    "        res_str = decode(chars)\n",
    "        x, y, w, h, theta = rboxes[k]\n",
    "        new_string = escape_latex(res_str).lower().strip()\n",
    "#         segmented_words.append(new_string)\n",
    "#         raw_preds.append(new_string)\n",
    "        new_string = new_string.split(' ')\n",
    "        segmented_word = []\n",
    "        for t in new_string:\n",
    "            raw_preds.append(t)\n",
    "            for q in LM.segment.segment(t):\n",
    "                segmented_word.append(q)\n",
    "        for word in segmented_word:\n",
    "            word = LM.clean.correction(word)\n",
    "            segmented_words.append(word)\n",
    "            \n",
    "#     segmented_words2 = []\n",
    "#     for k in range(len(res_crnn)):\n",
    "#         chars = [alphabet[c] for c in np.argmax(res_crnn[k], axis=1)]        \n",
    "#         res_str = decode(chars)\n",
    "#         x, y, w, h, theta = rboxes[k]\n",
    "#         new_string = escape_latex(res_str).lower()\n",
    "#         segmented_words2.append(new_string)\n",
    "        \n",
    "#     segmented_words3 = []\n",
    "#     for k in range(len(res_crnn)):\n",
    "#         chars = [alphabet[c] for c in np.argmax(res_crnn[k], axis=1)]        \n",
    "#         res_str = decode(chars)\n",
    "#         x, y, w, h, theta = rboxes[k]\n",
    "#         new_string = escape_latex(res_str).lower()\n",
    "#         segmented_word = segment.segment(new_string)\n",
    "#         for word in segmented_word:\n",
    "#             segmented_words3.append(word)\n",
    "    \n",
    "    end = time.time()\n",
    "    took = end-start\n",
    "#     print(\"Took:\", took)\n",
    "    total_time+=took\n",
    "    for j in range(len(texts)):\n",
    "        texts[j] = texts[j].lower().strip()\n",
    "    segmented_words = raw_preds    \n",
    "    \n",
    "    dummy_texts = texts.copy()\n",
    "    dummy_segmented_words = segmented_words.copy()\n",
    "    num_correct = 0\n",
    "    tp = 0; tn = 0; fp = 0; fn = 0\n",
    "    print(\"++++++++++++ BEFORE +++++++++++++\")\n",
    "    print(\"GT:\", texts)\n",
    "    print(\"PR:\", segmented_words)\n",
    "    print(\"RW:\", raw_preds)\n",
    "    \n",
    "    for a in range(len(segmented_words)):\n",
    "        pred_word = segmented_words[a]\n",
    "        if pred_word in dummy_texts:\n",
    "            dummy_texts.remove(pred_word)\n",
    "            dummy_segmented_words.remove(pred_word)\n",
    "            num_correct+=1\n",
    "            tp+=1\n",
    "    print(\"\\n++++++++++++ AFTER +++++++++++++\")   \n",
    "    fn = len(dummy_texts)\n",
    "    fp = len(dummy_segmented_words)\n",
    "    print(\"GT:\", dummy_texts)\n",
    "    print(\"PR:\", dummy_segmented_words)\n",
    "    print(\"RW:\", [item for item in raw_preds if item not in segmented_words])\n",
    "#     print(\"RW:\", raw_preds)   \n",
    "    print(\"\\n++++++++++++++++++++++++++++++++\")\n",
    "    print(\"TP:\", tp)\n",
    "    print(\"FP:\", fp)\n",
    "    print(\"FN:\", fn)\n",
    "    total_tp+=tp\n",
    "    total_fp+=fp\n",
    "    total_fn+=fn\n",
    "    \n",
    "    p = precision(tp, fp)\n",
    "    r = recall(tp, fn)\n",
    "    f = fscore(p, r)\n",
    "    print(\"PRECISION:\", p)\n",
    "    print(\"RECALL:\", r)\n",
    "    print(\"FSCORE:\", f)\n",
    "    \n",
    "    total_p+=p\n",
    "    total_r+=r\n",
    "    total_f+=f\n",
    "            \n",
    "    acc = num_correct/len(texts)\n",
    "    print(\"ACCURACY:\", acc)\n",
    "    total_correct+=num_correct\n",
    "    total_imgs+=1\n",
    "    total_text+=len(texts)\n",
    "    total_accuracy+=acc\n",
    "    print(\"\\n=============================================================================\\n\")\n",
    "print(\"Total Correct:\", total_correct)\n",
    "print(\"Total Images:\", total_imgs)\n",
    "print(\"Total Text:\", total_text)\n",
    "print(\"Total Time:\", total_time)\n",
    "print(\"Total Accuracy:\", total_accuracy)\n",
    "print(\"Total Precision:\", total_p)\n",
    "print(\"Total Recall:\", total_r)\n",
    "print(\"Total Fscore:\", total_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(total_correct/total_text)\n",
    "# print(total_imgs/total_time)\n",
    "# print(total_accuracy/total_imgs)\n",
    "# print(\"\\n\")\n",
    "# print(\"P:\", total_p/total_imgs)\n",
    "# print(\"R:\", total_r/total_imgs)\n",
    "# print(\"F:\", fscore(total_p/total_imgs, total_r/total_imgs))\n",
    "# print(\"F:\", total_f/total_imgs)\n",
    "# print(\"\\n\")\n",
    "# print(total_tp)\n",
    "# print(total_fp)\n",
    "# print(total_fn)\n",
    "# print(\"\\n\")\n",
    "# print(\"P:\", precision(total_tp, total_fp))\n",
    "# print(\"R:\", recall(total_tp, total_fn))\n",
    "# print(\"F:\", fscore(precision(total_tp, total_fp), recall(total_tp, total_fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from crnn_data import crop_words\n",
    "# from crnn_utils import decode\n",
    "# from sl_utils import rbox_to_polygon, polygon_to_rbox\n",
    "# from ssd_viz import plot_box, escape_latex\n",
    "\n",
    "# gtu = gt_util_synth\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# total_time = 0\n",
    "# for k in range(0, gtu.num_samples, 16):\n",
    "# #     boxes = gtu.data[k][:,-8:]\n",
    "# #     print(boxes.shape)\n",
    "    \n",
    "#     img_path = os.path.join(gtu.image_path, gtu.image_names[k])\n",
    "#     img = cv2.imread(img_path)\n",
    "    \n",
    "# #     boxes = np.copy(gtu.data[k][:,:-2])\n",
    "# #     print(boxes)\n",
    "# #     texts = np.copy(gtu.text[k])\n",
    "\n",
    "# #     mask = np.array([not (np.any(b < 0.) or np.any(b > 1.)) for b in boxes])\n",
    "# #     boxes = boxes[mask]\n",
    "# #     texts = texts[mask]\n",
    "\n",
    "# #     if len(boxes) == 0: continue\n",
    "\n",
    "# #     try:\n",
    "# #         words = crop_words(img, boxes, input_height, width=input_width, grayscale=True)\n",
    "# #     except Exception as e:\n",
    "# #         import traceback\n",
    "# #         print(traceback.format_exc())\n",
    "# #         print(img_path)\n",
    "# #         continue\n",
    "\n",
    "# #     # drop words with width > height here\n",
    "# #     mask = np.array([w.shape[1] > w.shape[0] for w in words])\n",
    "# #     words = np.asarray(words)[mask]\n",
    "# #     texts = texts[mask]\n",
    "\n",
    "# #     for box in boxes:\n",
    "# #         for i in range(len(box)):\n",
    "# #             if i % 2 == 0:\n",
    "# #                 box[i] = box[i]/512\n",
    "# #             else:\n",
    "# #                 box[i] = box[i]/512\n",
    "# #     words = crop_words(img, boxes, input_height, width=input_width, grayscale=True)\n",
    "# #     words = np.asarray([w.transpose(1,0,2) for w in words])\n",
    "    \n",
    "#     boxes = np.copy(gtu.data[k][:,:-gtu.num_classes])\n",
    "#     texts = np.copy(gtu.text[k])    \n",
    "#     words = crop_words(img, boxes, input_height, width=input_width, grayscale=True)\n",
    "#     words = np.asarray([w.transpose(1,0,2) for w in words])\n",
    "#     start = time.time()\n",
    "#     if len(words) > 0:\n",
    "#         res_crnn = crnn_model.predict(words)\n",
    "#     else:\n",
    "#         res_crnn = []\n",
    "    \n",
    "#     total+=len(texts)\n",
    "#     for i in range(len(res_crnn)):\n",
    "#         chars = [alphabet[c] for c in np.argmax(res_crnn[i], axis=1)]       \n",
    "#         res_str = decode(chars)\n",
    "# #         print(escape_latex(res_str), texts[i])\n",
    "#         if escape_latex(res_str).lower() == texts[i].lower():\n",
    "#             correct+=1\n",
    "# #     print(\"=============================================================================\")\n",
    "#     end = time.time()\n",
    "#     total_time+=(end-start)\n",
    "#     print(\"Took:\", (end-start))\n",
    "# print(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_imgs = 0\n",
    "# for k in range(0, gtu.num_samples, 16):\n",
    "#     num_imgs+=1\n",
    "# print(correct/total)\n",
    "# print(num_imgs/total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video End to end - no tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_video(rootpath, filetype):\n",
    "    vids = []\n",
    "    fnames = []\n",
    "    for filename in glob.glob(rootpath + \"*.\" + filetype):\n",
    "        actual_filename = filename.split(\"/\")[-1]\n",
    "        fnames.append(actual_filename.split(\".\")[0])\n",
    "        vids.append(imageio.get_reader(filename,  'ffmpeg'))\n",
    "    fnames, vids = zip(*sorted(zip(fnames, vids)))\n",
    "    return fnames, vids\n",
    "\n",
    "def load_video_gt():\n",
    "    paths = glob.glob(\"./data/fixed_video_gt/Fixed_*.txt\")\n",
    "    paths.sort()\n",
    "    gt = []\n",
    "    for path in paths:\n",
    "        with open(path) as f:\n",
    "            content = f.read().splitlines()\n",
    "        video_gt = []\n",
    "        frame_gt = []\n",
    "        for i in range(len(content)):\n",
    "            if content[i] == \"FRAME\":\n",
    "                video_gt.append(frame_gt)\n",
    "                frame_gt = []\n",
    "            else:\n",
    "                lbl = content[i].split()\n",
    "                lbl = lbl[0].split(\",\")\n",
    "                for i in range(8):\n",
    "                    lbl[i] = float(lbl[i])\n",
    "                frame_gt.append(lbl)\n",
    "        gt.append(video_gt)\n",
    "    return gt\n",
    "\n",
    "def remove_values_from_list(the_list, val):\n",
    "    return [value for value in the_list if value != val]\n",
    "\n",
    "def load_testfourgt():\n",
    "    with open('./data/testfourgt.txt') as f:\n",
    "        content = f.read().splitlines()\n",
    "    gt = []\n",
    "    for i in range(len(content)):\n",
    "        gttexts = content[i].split(' ')\n",
    "        for j in range(len(gttexts)):\n",
    "            gttexts[j] = gttexts[j].lower()\n",
    "        gt.append(remove_values_from_list(gttexts, ''))\n",
    "#         if gttexts[j] != '':\n",
    "#             gt.append(gttexts)\n",
    "#         else:\n",
    "#             gt.append([])\n",
    "    return gt\n",
    "\n",
    "# video_names, videos = load_video(\"./data/icdar_2015_text_in_video/training/\", \"mp4\")\n",
    "# gt = load_video_gt()\n",
    "testfourgt = load_testfourgt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'appw', '823', 'halton', 'honda', 'ontario', 'burl', 'gton']\n"
     ]
    }
   ],
   "source": [
    "print(testfourgt[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def postprocess_detections(preds, segment_threshold=0.4, link_threshold=0.3):\n",
    "#     res = prior_util.decode(preds[0], segment_threshold=segment_threshold, link_threshold=link_threshold, debug=False)\n",
    "#     rboxes = res\n",
    "#     if len(rboxes) == 0:\n",
    "#         return []\n",
    "\n",
    "#     bh = rboxes[:,3]\n",
    "#     rboxes[:,2] += bh * 0.2\n",
    "#     rboxes[:,3] += bh * 0.2\n",
    "\n",
    "#     boxes = []\n",
    "#     for r in rboxes:\n",
    "#         ds = r[:5]\n",
    "#         r2p = rbox_to_polygon(ds)\n",
    "#         boxes.append(r2p)\n",
    "\n",
    "#     boxes = np.asarray(boxes)\n",
    "#     boxes = np.flip(boxes, axis=1) \n",
    "#     boxes = np.reshape(boxes, (-1, 8))\n",
    "\n",
    "#     boxes_mask_a = np.array([b[2] > b[3] for b in rboxes]) \n",
    "#     boxes_mask_b = np.array([not (np.any(b < 0) or np.any(b > image_size[0])) for b in boxes]) \n",
    "#     boxes_mask = np.logical_and(boxes_mask_a, boxes_mask_b)\n",
    "\n",
    "#     boxes = boxes[boxes_mask]\n",
    "#     rboxes = rboxes[boxes_mask]\n",
    "#     if len(boxes) == 0:\n",
    "#         boxes = np.empty((0,8))\n",
    "#     return boxes\n",
    "\n",
    "# def recognize_detected_text(img, boxes):\n",
    "#     words = crop_words(img, boxes/image_size[0], input_height, width=input_width, grayscale=True)\n",
    "#     words = np.asarray([w.transpose(1,0,2) for w in words])\n",
    "#     if len(words) > 0:\n",
    "#         res_crnn = crnn_model.predict(words)\n",
    "#     else:\n",
    "#         res_crnn = []   \n",
    "        \n",
    "#     segmented_words = []\n",
    "#     raw_preds = []\n",
    "#     for k in range(len(res_crnn)):\n",
    "#         chars = [alphabet[c] for c in np.argmax(res_crnn[k], axis=1)]        \n",
    "#         res_str = decode(chars)\n",
    "#         new_string = escape_latex(res_str).lower().strip()\n",
    "#         new_string = new_string.split(' ')\n",
    "#         segmented_word = []\n",
    "#         for t in new_string:\n",
    "# #             raw_preds.append(t)\n",
    "# #             segmented_word.append(t)\n",
    "#             for q in segment.segment(t):\n",
    "#                 segmented_word.append(q)\n",
    "#         for word in segmented_word:\n",
    "#             word = clean.correction(word)\n",
    "#             segmented_words.append(word)\n",
    "#     return segmented_words\n",
    "        \n",
    "# def flatten(inp):\n",
    "#     new_list = []\n",
    "#     for i in inp:\n",
    "#         for j in i:\n",
    "#             new_list.append(j)\n",
    "#     return new_list\n",
    "\n",
    "\n",
    "# def show_video_with_preds(video_path, labels, show_text=False):\n",
    "#     camera = cv2.VideoCapture(video_path)\n",
    "#     total_frame_count = int(camera.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     _, frame = camera.read()\n",
    "#     fps = camera.get(cv2.CAP_PROP_FPS)\n",
    "#     counter = 0\n",
    "#     total_correct = 0\n",
    "#     total_imgs = 0\n",
    "#     total_text = 0\n",
    "#     total_time = 0\n",
    "#     total_accuracy = 0\n",
    "\n",
    "#     total_p = 0\n",
    "#     total_r = 0\n",
    "#     total_f = 0\n",
    "\n",
    "#     total_tp = 0\n",
    "#     total_tn = 0\n",
    "#     total_fp = 0\n",
    "#     total_fn = 0\n",
    "#     start = time.time()\n",
    "#     while True:\n",
    "#         (grabbed, frame) = camera.read()\n",
    "#         if not grabbed:\n",
    "#             break\n",
    "#         frame = cv2.rotate(frame,rotateCode = 0)\n",
    "#         current_color_frame = cv2.resize(frame, (image_size[1], image_size[1]))\n",
    "#         inputs = np.asarray([preprocess(current_color_frame, image_size)])\n",
    "#         preds = model.predict(inputs, batch_size=1, verbose=1)\n",
    "#         boxes = postprocess_detections(preds, segment_threshold=0.6, link_threshold=0.20)\n",
    "#         frame_preds = []\n",
    "#         raw_preds = []\n",
    "#         if len(boxes) > 0:\n",
    "#             rw = recognize_detected_text(current_color_frame, boxes)\n",
    "# #             frame_preds.append(sg)\n",
    "#             raw_preds.append(rw)\n",
    "# #             frame_preds = flatten(frame_preds)\n",
    "#             frame_preds = flatten(raw_preds)\n",
    "#         frame_gts = labels[counter]\n",
    "# #         frame_gts = []\n",
    "# #         for label in frame_labels:\n",
    "# #             if label[-1] == \"##DONT#CARE##\":\n",
    "# #                 continue \n",
    "# #             frame_gts.append(label[-1].lower())\n",
    "        \n",
    "#         num_correct = 0\n",
    "#         tp = 0; tn = 0; fp = 0; fn = 0\n",
    "#         dummy_texts = frame_gts.copy()\n",
    "#         dummy_segmented_words = frame_preds.copy()\n",
    "#         print(\"GT:\", dummy_texts)\n",
    "#         print(\"PR:\", dummy_segmented_words)\n",
    "# #         print(\"RW:\", raw_preds)\n",
    "#         for a in range(len(frame_preds)):\n",
    "#             pred_word = frame_preds[a]\n",
    "#             if pred_word in dummy_texts:\n",
    "#                 dummy_texts.remove(pred_word)\n",
    "#                 dummy_segmented_words.remove(pred_word)\n",
    "#                 num_correct+=1\n",
    "#                 tp+=1\n",
    "#         print('\\n')\n",
    "#         print(\"GT:\", dummy_texts)\n",
    "#         print(\"PR:\", dummy_segmented_words)\n",
    "#         print(\"-\"*100)\n",
    "#         fn = len(dummy_texts)\n",
    "#         fp = len(dummy_segmented_words)\n",
    "#         print(tp, fp, fn)\n",
    "#         total_tp+=tp\n",
    "#         total_fp+=fp\n",
    "#         total_fn+=fn\n",
    "#         p = precision(tp, fp)\n",
    "#         r = recall(tp, fn)\n",
    "#         f = fscore(p, r)\n",
    "#         total_p+=p\n",
    "#         total_r+=r\n",
    "#         total_f+=f\n",
    "#         if len(frame_gts) == 0:\n",
    "#             acc = 0\n",
    "#         else:\n",
    "#             acc = num_correct/len(frame_gts)\n",
    "#         total_correct+=num_correct\n",
    "#         total_imgs+=1\n",
    "#         total_text+=len(frame_gts)\n",
    "#         total_accuracy+=acc\n",
    "    \n",
    "#         counter += 1\n",
    "#         cv2.imshow(\"Current Frame\", current_color_frame)    \n",
    "#         cv2.waitKey(1)\n",
    "        \n",
    "#     camera.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     end = time.time()\n",
    "#     elapsed = end-start\n",
    "#     print(\"Number of Frames:\", total_frame_count)\n",
    "#     print(\"Elapsed Time:\", elapsed)\n",
    "#     total_time+=elapsed\n",
    "#     print(\"Average FPS:\", total_frame_count / elapsed)\n",
    "#     print(total_correct,\n",
    "#             total_imgs,\n",
    "#             total_text,\n",
    "#             total_time,\n",
    "#             total_accuracy,\n",
    "#             total_p,\n",
    "#             total_r,\n",
    "#             total_f,\n",
    "#             total_tp,\n",
    "#             total_tn,\n",
    "#             total_fp,\n",
    "#             total_fn)\n",
    "#     print(precision(total_tp, total_fp))\n",
    "#     print(recall(total_tp, total_fn))\n",
    "#     print(fscore(precision(total_tp, total_fp), recall(total_tp, total_fn)))\n",
    "    \n",
    "# # video_index = 17\n",
    "# # video_path = \"./data/icdar_2015_text_in_video/training/\" + video_names[video_index] + \".mp4\"\n",
    "# video_path = \"./data/testfour.mov\"\n",
    "# # show_video_with_preds(video_path, gt[video_index], show_text=False)\n",
    "# show_video_with_preds(video_path, testfourgt, show_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video end-to-end with tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "GT: ['2']\n",
      "RW: []\n",
      "\n",
      "\n",
      "GT: ['2']\n",
      "RW: []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0 0 1\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "GT: ['2']\n",
      "RW: []\n",
      "\n",
      "\n",
      "GT: ['2']\n",
      "RW: []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0 0 1\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "GT: ['2']\n",
      "RW: []\n",
      "\n",
      "\n",
      "GT: ['2']\n",
      "RW: []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0 0 1\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "GT: ['2']\n",
      "RW: []\n",
      "\n",
      "\n",
      "GT: ['2']\n",
      "RW: []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0 0 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-035d28a99928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/testfour.mov\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;31m# show_video_with_preds(video_path, gt[video_index], show_text=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m \u001b[0mshow_video_with_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestfourgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-035d28a99928>\u001b[0m in \u001b[0;36mshow_video_with_preds\u001b[0;34m(video_path, labels, show_text)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;31m#             print(\"IF\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_color_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpostprocess_detections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1798\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1800\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lk_params = dict(winSize = (10, 10), \n",
    "                 maxLevel = 8, \n",
    "                 criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 100, 0.1))\n",
    "\n",
    "def track_point(old_frame, new_frame, old_points):\n",
    "    new_points, status, error = cv2.calcOpticalFlowPyrLK(old_frame, new_frame, old_points, None, **lk_params)\n",
    "    return new_points, status\n",
    "\n",
    "def draw_bounding_box(frame, box, color):\n",
    "    vrx = np.array(box, np.int32)\n",
    "    vrx = vrx.reshape((-1,1,2))\n",
    "    frame = cv2.polylines(frame, [vrx], True, color, 2)\n",
    "    return frame\n",
    "\n",
    "def draw_text(frame, text, box):\n",
    "    avg_x = int(round((box[0] + box[2] + box[4] + box[6]) / 4))\n",
    "    half_width = int(round((max(box[0], box[2], box[4], box[6]) - min(box[0], box[2], box[4], box[6]))/2))\n",
    "    avg_y = int(round((box[1] + box[3] + box[5] + box[7]) / 4))\n",
    "    cv2.putText(frame, text, (avg_x-half_width, avg_y+30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "    \n",
    "# def postprocess_detections(preds, segment_threshold=0.4, link_threshold=0.3):\n",
    "#     res = prior_util.decode(preds[0], segment_threshold=segment_threshold, link_threshold=link_threshold, debug=False)\n",
    "#     rboxes = res\n",
    "#     if len(rboxes) == 0:\n",
    "#         return []\n",
    "\n",
    "#     bh = rboxes[:,3]\n",
    "#     rboxes[:,2] += bh * 0.2\n",
    "#     rboxes[:,3] += bh * 0.2\n",
    "\n",
    "#     boxes = []\n",
    "#     for r in rboxes:\n",
    "#         ds = r[:5]\n",
    "#         r2p = rbox_to_polygon(ds)\n",
    "#         boxes.append(r2p)\n",
    "\n",
    "#     boxes = np.asarray(boxes)\n",
    "#     boxes = np.flip(boxes, axis=1) \n",
    "#     boxes = np.reshape(boxes, (-1, 8))\n",
    "\n",
    "#     boxes_mask_a = np.array([b[2] > b[3] for b in rboxes]) \n",
    "#     boxes_mask_b = np.array([not (np.any(b < 0) or np.any(b > image_size[0])) for b in boxes]) \n",
    "#     boxes_mask = np.logical_and(boxes_mask_a, boxes_mask_b)\n",
    "\n",
    "#     boxes = boxes[boxes_mask]\n",
    "#     rboxes = rboxes[boxes_mask]\n",
    "#     if len(boxes) == 0:\n",
    "#         boxes = np.empty((0,8))\n",
    "#     return boxes\n",
    "\n",
    "# def recognize_detected_text(img, boxes):\n",
    "#     words = crop_words(img, boxes/image_size[0], input_height, width=input_width, grayscale=True)\n",
    "#     words = np.asarray([w.transpose(1,0,2) for w in words])\n",
    "#     if len(words) > 0:\n",
    "#         res_crnn = crnn_model.predict(words)\n",
    "#     else:\n",
    "#         res_crnn = []        \n",
    "#     recognized_text = []\n",
    "#     for i in range(len(res_crnn)):\n",
    "#         chars = [alphabet[c] for c in np.argmax(res_crnn[i], axis=1)]\n",
    "#         res_str = decode(chars)\n",
    "#         recognized_text.append(res_str)\n",
    "#     return recognized_text\n",
    "\n",
    "def shift_box(initial_points, new_points, status, box):\n",
    "    delta_x = 0; delta_y = 0\n",
    "    delta_x_list = []; delta_y_list = []\n",
    "    for k in range(len(initial_points)):\n",
    "        if status[k] == 0:\n",
    "            continue\n",
    "        delta_x = delta_x - (initial_points[k][0][0] - new_points[k][0][0])\n",
    "        delta_y = delta_y - (initial_points[k][0][1] - new_points[k][0][1])\n",
    "        delta_x_list.append(delta_x)\n",
    "        delta_y_list.append(delta_y)\n",
    "    delta_x_list.sort()\n",
    "    delta_y_list.sort()\n",
    "    median_delta_x = statistics.median(delta_x_list)\n",
    "    median_delta_y = statistics.median(delta_y_list)\n",
    "    \n",
    "    delta_x = 0; delta_y = 0\n",
    "    THRES = 1.1\n",
    "    for k in range(len(initial_points)):\n",
    "        if status[k] == 0:\n",
    "            continue\n",
    "        if (abs(initial_points[k][0][0] - new_points[k][0][0])) < (abs(THRES * median_delta_x)) and (abs(initial_points[k][0][1] - new_points[k][0][1])) < (abs(THRES * median_delta_y)):\n",
    "            delta_x = delta_x - (initial_points[k][0][0] - new_points[k][0][0])\n",
    "            delta_y = delta_y - (initial_points[k][0][1] - new_points[k][0][1])\n",
    "    mean_delta_x = delta_x / len(initial_points)\n",
    "    mean_delta_y = delta_y / len(initial_points)\n",
    "\n",
    "    shifted_box = [box[0] + mean_delta_x, \n",
    "                   box[1] + mean_delta_y, \n",
    "                   box[2] + mean_delta_x, \n",
    "                   box[3] + mean_delta_y, \n",
    "                   box[4] + mean_delta_x,\n",
    "                   box[5] + mean_delta_y,\n",
    "                   box[6] + mean_delta_x,\n",
    "                   box[7] + mean_delta_y]\n",
    "    \n",
    "    broken = False\n",
    "    for i in range(len(shifted_box)):\n",
    "        if shifted_box[i] < 0:\n",
    "            broken = True\n",
    "        if (i%2 == 0) and (shifted_box[i] > image_size[1]):\n",
    "            broken = True\n",
    "        if (i%2 == 1) and (shifted_box[i] > image_size[0]):\n",
    "            broken = True\n",
    "            \n",
    "    return shifted_box, broken\n",
    "\n",
    "def create_text_mask(frame, box):\n",
    "    mask = np.zeros(frame.shape, dtype=np.uint8)\n",
    "    roi_corners = np.array([[(box[0], box[1]), (box[2], box[3]), (box[4], box[5]), (box[6], box[7])]], dtype=np.int32)\n",
    "    channel_count = frame.shape[2]\n",
    "    ignore_mask_color = (255,)*channel_count\n",
    "    cv2.fillPoly(mask, roi_corners, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(frame, mask)\n",
    "    gray_masked_image = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray_masked_image\n",
    "\n",
    "def create_padded_text_mask(frame, box, padding=10):\n",
    "    mask = np.zeros(frame.shape, dtype=np.uint8)\n",
    "    minX = min([box[0], box[2], box[4], box[6]]) - padding\n",
    "    maxX = max([box[0], box[2], box[4], box[6]]) + padding\n",
    "    minY = min([box[1], box[3], box[5], box[7]]) - padding\n",
    "    maxY = max([box[1], box[3], box[5], box[7]]) + padding\n",
    "    if minX < 0:\n",
    "        minX = 0\n",
    "    if maxX > image_size[1]:\n",
    "        maxX = image_size[1]\n",
    "    if minY < 0:\n",
    "        minY = 0\n",
    "    if maxY > image_size[0]:\n",
    "        maxY = image_size[0]\n",
    "        \n",
    "    roi_corners = np.array([[(minX, minY), (maxX, minY), (maxX, maxY), (minX, maxY)]], dtype=np.int32)\n",
    "    channel_count = frame.shape[2]\n",
    "    ignore_mask_color = (255,)*channel_count\n",
    "    cv2.fillPoly(mask, roi_corners, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(frame, mask)\n",
    "    gray_masked_image = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray_masked_image\n",
    "\n",
    "def generate_initial_tracking_points(frame, box):\n",
    "    gray_masked_image = create_text_mask(frame, box)\n",
    "    corners = cv2.goodFeaturesToTrack(gray_masked_image, 100, minDistance=1, qualityLevel=0.05)\n",
    "    corners = np.int0(corners)\n",
    "    if len(corners) < 10:\n",
    "        return np.array([[]], dtype=np.float32)\n",
    "    pnt_list = []\n",
    "    for corner in corners:\n",
    "        x, y = corner.ravel()\n",
    "        pnt = [x, y]\n",
    "        pnt_list.append(pnt)\n",
    "    initial_points = np.array(pnt_list, dtype=np.float32)\n",
    "    return initial_points.reshape((len(initial_points),1,2))\n",
    "\n",
    "def show_gt(frame, labels, counter, show_text=False):    \n",
    "    frame_labels = labels[counter]\n",
    "    for label in frame_labels:\n",
    "        if label[-1] == \"##DONT#CARE##\":\n",
    "            continue \n",
    "        \n",
    "        vrx = np.array(label[:8], np.int32)\n",
    "        vrx = vrx.reshape((-1,1,2))\n",
    "        frame = cv2.polylines(frame, [vrx], True, (0,255,255),2)\n",
    "        if show_text:\n",
    "            avg_x = int(round((label[0] + label[2] + label[4] + label[6]) / 4))\n",
    "            half_width = int(round((max(label[0], label[2], label[4], label[6]) - min(label[0], label[2], label[4], label[6]))/2))\n",
    "            avg_y = int(round((label[1] + label[3] + label[5] + label[7]) / 4))\n",
    "            cv2.putText(frame, label[-1], (avg_x-half_width, avg_y+30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "def recognize_and_display(img, boxes, frame, show_text=False):\n",
    "    recognized_text = recognize_detected_text(img, boxes)\n",
    "    if show_text:\n",
    "        for i in range(len(recognized_text)):\n",
    "            draw_text(frame, recognized_text[i], boxes[i])\n",
    "\n",
    "def get_orb_features(frame, box, old_frame, new_frame):\n",
    "    orb = cv2.ORB_create()\n",
    "    old_mask = create_text_mask(frame, box)\n",
    "    new_mask = create_padded_text_mask(frame, box, padding=10)\n",
    "    \n",
    "    kp1, des1 = orb.detectAndCompute(new_frame, new_mask)\n",
    "    kp2, des2 = orb.detectAndCompute(old_frame, old_mask)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1,des2)\n",
    "    if len(matches) < 10:\n",
    "        return [], []\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    matches = matches[:10]\n",
    "    \n",
    "    # what if the number of matches is too low or 0?\n",
    "\n",
    "    list_kp1 = []\n",
    "    list_kp2 = []\n",
    "    for mat in matches:\n",
    "        img1_idx = mat.queryIdx\n",
    "        img2_idx = mat.trainIdx\n",
    "        (x1,y1) = kp1[img1_idx].pt\n",
    "        (x2,y2) = kp2[img2_idx].pt\n",
    "        list_kp1.append([x1, y1])\n",
    "        list_kp2.append([x2, y2])\n",
    "    list_kp1 = np.array(list_kp1, dtype=np.float32)\n",
    "    list_kp2 = np.array(list_kp2, dtype=np.float32)\n",
    "    \n",
    "#     for p in range(len(list_kp1)):\n",
    "#         point = list_kp1[p]\n",
    "#         point2 = list_kp2[p]\n",
    "#         cv2.circle(frame, (int(round(point[0])), int(round(point[1]))), 3, (255, 255, 0), -1) # cyan\n",
    "#         cv2.circle(frame, (int(round(point2[0])), int(round(point2[1]))), 3, (0, 255, 255), -1) #yellow\n",
    "\n",
    "    return list_kp1.reshape((len(list_kp1),1,2)), list_kp2.reshape((len(list_kp2),1,2))\n",
    "\n",
    "def track_quadrant(previous_color_frame, previous_gray_frame, current_color_frame, current_gray_frame, quadx, quady):\n",
    "    try:\n",
    "        img = previous_gray_frame[quady:quady+50, quadx:quadx+50]\n",
    "        corners = cv2.goodFeaturesToTrack(img, 100, minDistance=1, qualityLevel=0.05)\n",
    "        corners = np.int0(corners)\n",
    "        if len(corners) < 10:\n",
    "            return 999,999\n",
    "        pnt_list = []\n",
    "        for corner in corners:\n",
    "            x, y = corner.ravel()\n",
    "            pnt = [x, y]\n",
    "            pnt_list.append(pnt)\n",
    "        initial_points = np.array(pnt_list, dtype=np.float32)\n",
    "        initial_points = initial_points.reshape((len(initial_points),1,2))\n",
    "        if len(initial_points) == 0:\n",
    "            return 999,999\n",
    "        d_new_points, d_status, d_error = cv2.calcOpticalFlowPyrLK(previous_gray_frame, current_gray_frame, initial_points, None, **lk_params)\n",
    "\n",
    "        delta_x = 0; delta_y = 0\n",
    "        delta_x_list = []; delta_y_list = []\n",
    "        for k in range(len(initial_points)):\n",
    "            if d_status[k] == 0:\n",
    "                continue\n",
    "            delta_x = delta_x - (initial_points[k][0][0] - d_new_points[k][0][0])\n",
    "            delta_y = delta_y - (initial_points[k][0][1] - d_new_points[k][0][1])\n",
    "            delta_x_list.append(delta_x)\n",
    "            delta_y_list.append(delta_y)\n",
    "        delta_x_list.sort()\n",
    "        delta_y_list.sort()\n",
    "        median_delta_x = statistics.median(delta_x_list)\n",
    "        median_delta_y = statistics.median(delta_y_list)\n",
    "\n",
    "        delta_x = 0; delta_y = 0\n",
    "        THRES = 1.1\n",
    "        for k in range(len(initial_points)):\n",
    "            if d_status[k] == 0:\n",
    "                continue\n",
    "            if (abs(initial_points[k][0][0] - d_new_points[k][0][0])) < (abs(THRES * median_delta_x)) and (abs(initial_points[k][0][1] - d_new_points[k][0][1])) < (abs(THRES * median_delta_y)):\n",
    "                delta_x = delta_x - (initial_points[k][0][0] - d_new_points[k][0][0])\n",
    "                delta_y = delta_y - (initial_points[k][0][1] - d_new_points[k][0][1])\n",
    "        mean_delta_x = delta_x / len(initial_points)\n",
    "        mean_delta_y = delta_y / len(initial_points)\n",
    "        return mean_delta_x, mean_delta_y\n",
    "    except:\n",
    "        return 999,999\n",
    "        \n",
    "# def show_video_with_preds(video_path, labels, show_text=False):\n",
    "#     camera = cv2.VideoCapture(video_path)\n",
    "#     total_frame_count = int(camera.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     old_points = np.array([[]])\n",
    "#     _, frame = camera.read()\n",
    "#     old_color_frame = cv2.resize(frame, (image_size[1], image_size[0]))\n",
    "#     old_gray_frame = cv2.cvtColor(old_color_frame, cv2.COLOR_BGR2GRAY)\n",
    "#     fps = camera.get(cv2.CAP_PROP_FPS)\n",
    "#     COUNTER = 1\n",
    "#     LAST_FRAME_NUMBER_WITH_DETECTION = -4\n",
    "#     NUMBER_OF_FRAMES_SINCE_LAST_DETECTION = 0\n",
    "#     old_boxes = []\n",
    "#     totalX = 0; totalY = 0\n",
    "    \n",
    "#     while True:\n",
    "#         (grabbed, frame) = camera.read()\n",
    "#         if not grabbed:\n",
    "#             break\n",
    "        \n",
    "#         current_color_frame = cv2.resize(frame, (image_size[1], image_size[1]))\n",
    "#         current_color_frame_copy = current_color_frame.copy()\n",
    "#         current_gray_frame = cv2.cvtColor(current_color_frame, cv2.COLOR_BGR2GRAY)\n",
    "#         NUMBER_OF_FRAMES_SINCE_LAST_DETECTION = COUNTER - LAST_FRAME_NUMBER_WITH_DETECTION\n",
    "        \n",
    "#         start = time.time()\n",
    "# #         a = cv2.resize(old_gray_frame, (150, 150))\n",
    "# #         b = cv2.resize(current_gray_frame, (150, 150))\n",
    "# #         c = cv2.resize(old_color_frame, (150, 150))\n",
    "# #         d = cv2.resize(current_color_frame, (150, 150))\n",
    "        \n",
    "# #         x1, y1 = track_quadrant(c, a, d, b, 0, 0)\n",
    "# #         x2, y2 = track_quadrant(c, a, d, b, 50, 0)\n",
    "# #         x3, y3 = track_quadrant(c, a, d, b, 100, 0)\n",
    "# #         x4, y4 = track_quadrant(c, a, d, b, 0, 50)\n",
    "# #         x5, y5 = track_quadrant(c, a, d, b, 50, 50)\n",
    "# #         x6, y6 = track_quadrant(c, a, d, b, 100, 50)\n",
    "# #         x7, y7 = track_quadrant(c, a, d, b, 0, 100)\n",
    "# #         x8, y8 = track_quadrant(c, a, d, b, 50, 100)\n",
    "# #         x9, y9 = track_quadrant(c, a, d, b, 100, 100)\n",
    "        \n",
    "# #         print(x1,y1)\n",
    "# #         print(x2,y2)\n",
    "# #         print(x3,y3)\n",
    "# #         print(x4,y4)\n",
    "# #         print(x5,y5)\n",
    "# #         print(x6,y6)\n",
    "# #         print(x7,y7)\n",
    "# #         print(x8,y8)\n",
    "# #         print(x9,y9)\n",
    "        \n",
    "# #         if x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 < 600 and y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9 < 600:\n",
    "# #             threshold = 10\n",
    "# #             strong_right = False; strong_left = False; strong_down = False; strong_up = False\n",
    "# #             weak_right = False; weak_left = False; weak_down = False; weak_up = False\n",
    "# #             if x1 > 0 and x2 > 0 and x3 > 0 and x4 > 0 and x5 > 0 and x6 > 0 and x7 > 0 and x8 > 0 and x9:\n",
    "# #                 avgX = (x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9) / 9\n",
    "# #                 if avgX > threshold:\n",
    "# #                     strong_right = True\n",
    "# #                 else:\n",
    "# #                     weak_right = True\n",
    "\n",
    "# #             elif x1 < 0 and x2 < 0 and x3 < 0 and x4 < 0 and x5 < 0 and x6 < 0 and x7 < 0 and x8 < 0 and x9:\n",
    "# #                 avgX = (x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9) / 9\n",
    "# #                 if avgX > -threshold:\n",
    "# #                     strong_left = True\n",
    "# #                 else:\n",
    "# #                     weak_left = True\n",
    "\n",
    "# #             if y1 > 0 and y2 > 0 and y3 > 0 and y4 > 0 and y5 > 0 and y6 > 0 and y7 > 0 and y8 > 0 and y9:\n",
    "# #                 avgY = (y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9) / 9\n",
    "# #                 if avgY > threshold:\n",
    "# #                     strong_down = True\n",
    "# #                 else:\n",
    "# #                     weak_down = True\n",
    "\n",
    "# #             elif y1 < 0 and y2 < 0 and y3 < 0 and y4 < 0 and y5 < 0 and y6 < 0 and y7 < 0 and y8 < 0 and y9:\n",
    "# #                 avgY = (y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9) / 9\n",
    "# #                 if avgY > -threshold:\n",
    "# #                     strong_up = True\n",
    "# #                 else:\n",
    "# #                     weak_up = True\n",
    "\n",
    "# #             if strong_right and weak_down and weak_up:\n",
    "# #                 print(\"RIGHT\")\n",
    "# #                 ratio = avgX / 150\n",
    "# #                 ratio = ratio * 512\n",
    "# #                 section = int(128 * round(float(ratio)/128))\n",
    "# #                 cropped_image = current_color_frame[0:512, section:512]\n",
    "# #             elif strong_left and weak_down and weak_up:\n",
    "# #                 print(\"LEFT\")\n",
    "# #                 ratio = avgX / 150\n",
    "# #                 ratio = ratio * 512\n",
    "# #                 section = int(128 * round(float(ratio)/128))\n",
    "# #                 cropped_image = current_color_frame[0:512, 0:512-section]\n",
    "# #             elif strong_down and weak_left and weak_right:\n",
    "# #                 print(\"DOWN\")\n",
    "# #                 ratio = avgY / 150\n",
    "# #                 ratio = ratio * 512\n",
    "# #                 section = int(128 * round(float(ratio)/128))\n",
    "# #                 cropped_image = current_color_frame[section:512, 0:512]\n",
    "# #             elif strong_up and weak_left and weak_right:\n",
    "# #                 print(\"UP\")\n",
    "# #                 ratio = avgY / 150\n",
    "# #                 ratio = ratio * 512\n",
    "# #                 section = int(128 * round(float(ratio)/128))\n",
    "# #                 cropped_image = current_color_frame[0:512-section, 0:512]\n",
    "            \n",
    "        \n",
    "# #         print(\"took:\", time.time()-start)\n",
    "        \n",
    "#         if NUMBER_OF_FRAMES_SINCE_LAST_DETECTION > 3:\n",
    "#             inputs = np.asarray([preprocess(current_color_frame, image_size)])\n",
    "#             preds = model.predict(inputs, batch_size=1, verbose=1)\n",
    "#             boxes = postprocess_detections(preds, segment_threshold=0.6, link_threshold=0.2)\n",
    "#             if len(boxes) > 0:\n",
    "#                 LAST_FRAME_NUMBER_WITH_DETECTION = COUNTER\n",
    "#                 for box in boxes:\n",
    "#                     current_color_frame = draw_bounding_box(current_color_frame, box, (0,0,255))\n",
    "#                     current_color_frame_copy = draw_bounding_box(current_color_frame_copy, box, (255,0,255))\n",
    "#                 old_boxes = boxes\n",
    "#                 recognize_and_display(img, boxes, current_color_frame, show_text=show_text)\n",
    "    \n",
    "#         else:                    \n",
    "#             if len(old_boxes) > 0:\n",
    "#                 all_boxes = []\n",
    "#                 for box in old_boxes:\n",
    "#                     try:\n",
    "#                         initial_points = generate_initial_tracking_points(old_color_frame, box)\n",
    "#                         if len(initial_points) == 0:\n",
    "#                             continue\n",
    "#                         for pt in initial_points:\n",
    "#                             cv2.circle(old_color_frame,(pt[0][0], pt[0][1]), 3, (255,255,0), -1)\n",
    "#                         new_points, status = track_point(old_gray_frame, current_gray_frame, initial_points)\n",
    "#                         for i in range(len(new_points)):\n",
    "#                             if status[i] == 1:\n",
    "#                                 cv2.circle(current_color_frame,(new_points[i][0][0], new_points[i][0][1]), 3, (0,255,255), -1)\n",
    "#                         shifted_box, broken = shift_box(initial_points, new_points, status, box)\n",
    "#                         if broken:\n",
    "#                             continue\n",
    "#                         current_color_frame = draw_bounding_box(current_color_frame, shifted_box, (0,255,0))\n",
    "#                         all_boxes.append(shifted_box)\n",
    "#                         old_boxes = np.array(all_boxes)\n",
    "#                         recognize_and_display(img, boxes, current_color_frame, show_text=show_text)\n",
    "#                     except:\n",
    "#                         LAST_FRAME_NUMBER_WITH_DETECTION = COUNTER -5\n",
    "#                         break\n",
    "        \n",
    "# #         cv2.imshow(\"Current Frame\", current_color_frame)\n",
    "# #         cv2.imshow(\"Previous Frame\", old_color_frame)\n",
    "#         old_color_frame = current_color_frame_copy.copy()\n",
    "#         old_gray_frame = current_gray_frame.copy()\n",
    "#         cv2.waitKey(10)\n",
    "#         COUNTER += 1\n",
    "        \n",
    "#     camera.release()\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "#     cv2.waitKey(1)\n",
    "\n",
    "\n",
    "def postprocess_detections(preds, segment_threshold=0.4, link_threshold=0.3):\n",
    "    res = prior_util.decode(preds[0], segment_threshold=segment_threshold, link_threshold=link_threshold, debug=False)\n",
    "    rboxes = res\n",
    "    if len(rboxes) == 0:\n",
    "        return []\n",
    "\n",
    "    bh = rboxes[:,3]\n",
    "    rboxes[:,2] += bh * 0.2\n",
    "    rboxes[:,3] += bh * 0.2\n",
    "\n",
    "    boxes = []\n",
    "    for r in rboxes:\n",
    "        ds = r[:5]\n",
    "        r2p = rbox_to_polygon(ds)\n",
    "        boxes.append(r2p)\n",
    "\n",
    "    boxes = np.asarray(boxes)\n",
    "    boxes = np.flip(boxes, axis=1) \n",
    "    boxes = np.reshape(boxes, (-1, 8))\n",
    "\n",
    "    boxes_mask_a = np.array([b[2] > b[3] for b in rboxes]) \n",
    "    boxes_mask_b = np.array([not (np.any(b < 0) or np.any(b > image_size[0])) for b in boxes]) \n",
    "    boxes_mask = np.logical_and(boxes_mask_a, boxes_mask_b)\n",
    "\n",
    "    boxes = boxes[boxes_mask]\n",
    "    rboxes = rboxes[boxes_mask]\n",
    "    if len(boxes) == 0:\n",
    "        boxes = np.empty((0,8))\n",
    "    return boxes\n",
    "\n",
    "def recognize_detected_text(img, boxes):\n",
    "    words = crop_words(img, boxes/image_size[0], input_height, width=input_width, grayscale=True)\n",
    "    words = np.asarray([w.transpose(1,0,2) for w in words])\n",
    "    if len(words) > 0:\n",
    "        res_crnn = crnn_model.predict(words)\n",
    "    else:\n",
    "        res_crnn = []   \n",
    "        \n",
    "    segmented_words = []\n",
    "    raw_preds = []\n",
    "    for k in range(len(res_crnn)):\n",
    "        chars = [alphabet[c] for c in np.argmax(res_crnn[k], axis=1)]        \n",
    "        res_str = decode(chars)\n",
    "        new_string = escape_latex(res_str).lower().strip()\n",
    "        new_string = new_string.split(' ')\n",
    "        segmented_word = []\n",
    "        for t in new_string:\n",
    "#             raw_preds.append(t)\n",
    "#             segmented_word.append(t)\n",
    "            for q in segment.segment(t):\n",
    "                segmented_word.append(q)\n",
    "        for word in segmented_word:\n",
    "            word = clean.correction(word)\n",
    "            segmented_words.append(word)\n",
    "    return segmented_words\n",
    "        \n",
    "def flatten(inp):\n",
    "    new_list = []\n",
    "    for i in inp:\n",
    "        for j in i:\n",
    "            new_list.append(j)\n",
    "    return new_list\n",
    "\n",
    "\n",
    "def show_video_with_preds(video_path, labels, show_text=False):   \n",
    "    camera = cv2.VideoCapture(video_path)\n",
    "    total_frame_count = int(camera.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    _, frame = camera.read()\n",
    "    fps = camera.get(cv2.CAP_PROP_FPS)\n",
    "    old_points = np.array([[]])\n",
    "    old_color_frame = cv2.resize(frame, (image_size[1], image_size[0]))\n",
    "    old_gray_frame = cv2.cvtColor(old_color_frame, cv2.COLOR_BGR2GRAY)\n",
    "    COUNTER = 1\n",
    "    LAST_FRAME_NUMBER_WITH_DETECTION = -4\n",
    "    NUMBER_OF_FRAMES_SINCE_LAST_DETECTION = 0\n",
    "    old_boxes = []\n",
    "    totalX = 0; totalY = 0\n",
    "    \n",
    "    counter = 0\n",
    "    total_correct = 0\n",
    "    total_imgs = 0\n",
    "    total_text = 0\n",
    "    total_time = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    total_p = 0\n",
    "    total_r = 0\n",
    "    total_f = 0\n",
    "\n",
    "    total_tp = 0\n",
    "    total_tn = 0\n",
    "    total_fp = 0\n",
    "    total_fn = 0\n",
    "    start = time.time()\n",
    "    while True:\n",
    "        (grabbed, frame) = camera.read()\n",
    "        if not grabbed:\n",
    "            break\n",
    "        frame = cv2.rotate(frame,rotateCode = 0)\n",
    "        current_color_frame = cv2.resize(frame, (image_size[1], image_size[1]))\n",
    "        current_color_frame_copy = current_color_frame.copy()\n",
    "        current_gray_frame = cv2.cvtColor(current_color_frame, cv2.COLOR_BGR2GRAY)\n",
    "        NUMBER_OF_FRAMES_SINCE_LAST_DETECTION = COUNTER - LAST_FRAME_NUMBER_WITH_DETECTION\n",
    "           \n",
    "        frame_gts = labels[counter]\n",
    "        frame_preds = []\n",
    "        if NUMBER_OF_FRAMES_SINCE_LAST_DETECTION > 3:\n",
    "#             print(\"IF\")\n",
    "            inputs = np.asarray([preprocess(current_color_frame, image_size)])\n",
    "            preds = model.predict(inputs, batch_size=1, verbose=1)\n",
    "            boxes = postprocess_detections(preds, segment_threshold=0.6, link_threshold=0.2)\n",
    "            if len(boxes) > 0:\n",
    "                print(len(boxes))\n",
    "                LAST_FRAME_NUMBER_WITH_DETECTION = COUNTER\n",
    "                old_boxes = boxes\n",
    "                frame_preds.append(recognize_detected_text(current_color_frame, boxes))\n",
    "    \n",
    "        else:          \n",
    "#             print(\"ELSE\")\n",
    "            if len(old_boxes) > 0:\n",
    "                all_boxes = []\n",
    "                for box in old_boxes:\n",
    "                    try:\n",
    "                        initial_points = generate_initial_tracking_points(old_color_frame, box)\n",
    "                        if len(initial_points) == 0:\n",
    "                            continue\n",
    "                        new_points, status = track_point(old_gray_frame, current_gray_frame, initial_points)\n",
    "                        shifted_box, broken = shift_box(initial_points, new_points, status, box)\n",
    "                        if broken:\n",
    "                            continue\n",
    "                        all_boxes.append(shifted_box)\n",
    "                        old_boxes = np.array(all_boxes)\n",
    "                        \n",
    "                        \n",
    "                        #\n",
    "                        # Currently, we are making predictions on 'boxes' which is all the boxes.\n",
    "                        # However, these are from the detection, essentially giving us the same thing 4 times in a row.\n",
    "                        #\n",
    "                        # Instead we want to make a single recognition for each of the shifted boxes.\n",
    "                        # This should eliminate the duplication problem. But make sure that we are only making detections\n",
    "                        # every 4th time.\n",
    "                        #\n",
    "                        #\n",
    "#                         print('###############################################################')\n",
    "#                         print('boxes:', boxes)\n",
    "#                         print('\\n')\n",
    "#                         jsb = np.array([shifted_box])\n",
    "#                         print(jsb)\n",
    "#                         print('shifted_box:', jsb)\n",
    "#                         print('###############################################################')\n",
    "                        frame_preds.append(recognize_detected_text(current_color_frame, np.array([shifted_box])))\n",
    "                    except:\n",
    "                        print(\"TRACKING ERROR\")\n",
    "                        LAST_FRAME_NUMBER_WITH_DETECTION = COUNTER -5\n",
    "                        break\n",
    "        \n",
    "        frame_preds = flatten(frame_preds)\n",
    "#         print(\"GT:\", frame_gts)\n",
    "#         print(\"RW:\", frame_preds)\n",
    "        \n",
    "        num_correct = 0\n",
    "        tp = 0; tn = 0; fp = 0; fn = 0\n",
    "        dummy_texts = frame_gts.copy()\n",
    "        dummy_segmented_words = frame_preds.copy()\n",
    "        print(\"GT:\", dummy_texts)\n",
    "        print(\"RW:\", dummy_segmented_words)\n",
    "        for a in range(len(frame_preds)):\n",
    "            pred_word = frame_preds[a]\n",
    "            if pred_word in dummy_texts:\n",
    "                dummy_texts.remove(pred_word)\n",
    "                dummy_segmented_words.remove(pred_word)\n",
    "                num_correct+=1\n",
    "                tp+=1\n",
    "        print('\\n')\n",
    "        print(\"GT:\", dummy_texts)\n",
    "        print(\"RW:\", dummy_segmented_words)\n",
    "        print(\"-\"*100)\n",
    "        fn = len(dummy_texts)\n",
    "        fp = len(dummy_segmented_words)\n",
    "        print(tp, fp, fn)\n",
    "        total_tp+=tp\n",
    "        total_fp+=fp\n",
    "        total_fn+=fn\n",
    "        p = precision(tp, fp)\n",
    "        r = recall(tp, fn)\n",
    "        f = fscore(p, r)\n",
    "        total_p+=p\n",
    "        total_r+=r\n",
    "        total_f+=f\n",
    "        if len(frame_gts) == 0:\n",
    "            acc = 0\n",
    "        else:\n",
    "            acc = num_correct/len(frame_gts)\n",
    "        total_correct+=num_correct\n",
    "        total_imgs+=1\n",
    "        total_text+=len(frame_gts)\n",
    "        total_accuracy+=acc\n",
    "    \n",
    "        counter += 1\n",
    "        cv2.imshow(\"Current Frame\", current_color_frame)   \n",
    "        old_color_frame = current_color_frame_copy.copy()\n",
    "        old_gray_frame = current_gray_frame.copy()\n",
    "        cv2.waitKey(1)\n",
    "        COUNTER += 1\n",
    "        \n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    end = time.time()\n",
    "    elapsed = end-start\n",
    "    print(\"Number of Frames:\", total_frame_count)\n",
    "    print(\"Elapsed Time:\", elapsed)\n",
    "    total_time+=elapsed\n",
    "    print(\"Average FPS:\", total_frame_count / elapsed)\n",
    "    print(total_correct,\n",
    "            total_imgs,\n",
    "            total_text,\n",
    "            total_time,\n",
    "            total_accuracy,\n",
    "            total_p,\n",
    "            total_r,\n",
    "            total_f,\n",
    "            total_tp,\n",
    "            total_tn,\n",
    "            total_fp,\n",
    "            total_fn)\n",
    "    print(precision(total_tp, total_fp))\n",
    "    print(recall(total_tp, total_fn))\n",
    "    print(fscore(precision(total_tp, total_fp), recall(total_tp, total_fn)))\n",
    "    \n",
    "# video_index = 17\n",
    "# video_path = \"./data/icdar_2015_text_in_video/training/\" + video_names[video_index] + \".mp4\"\n",
    "video_path = \"./data/testfour.mov\"\n",
    "# show_video_with_preds(video_path, gt[video_index], show_text=False)\n",
    "show_video_with_preds(video_path, testfourgt, show_text=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
