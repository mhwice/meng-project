{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "from random import randint\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "from zipfile import ZipFile\n",
    "import imageio\n",
    "import time\n",
    "import statistics\n",
    "import editdistance\n",
    "import traceback\n",
    "import cProfile\n",
    "import LM.clean\n",
    "import LM.segment\n",
    "\n",
    "%matplotlib inline\n",
    "figure_size = 15\n",
    "plt.rcParams['figure.figsize'] = (figure_size, figure_size)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "from SegLink import datasets\n",
    "from SegLink.ssd_utils import load_weights\n",
    "from SegLink.ssd_data import InputGenerator, preprocess\n",
    "from SegLink.sl_model import SL512, SL512v2\n",
    "from SegLink.sl_utils import PriorUtil, rbox_to_polygon, polygon_to_rbox\n",
    "from SegLink.sl_metric import evaluate_results, fscore\n",
    "from SegLink.ssd_viz import plot_box, escape_latex\n",
    "from SegLink.ssd_training import Logger\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import SGD, Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "from CRNN.crnn_model import CRNN, CRNNv2\n",
    "from CRNN.crnn_data import InputGenerator, crop_words \n",
    "from CRNN.crnn_utils import alphabet87 as alphabet\n",
    "from CRNN.crnn_utils import decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dsodmodel = DSODSL512()\n",
    "# dsodmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_synthtext import GTUtility\n",
    "with open('gt_util_synthtext_seglink.pkl', 'rb') as f:\n",
    "    gt_util = pickle.load(f)\n",
    "gt_util_train, gt_util_other = gt_util.split(gt_util, split=0.5)\n",
    "gt_util_val, foo = gt_util.split(gt_util_other, split=0.03)\n",
    "gt_util_test, bar = gt_util.split(foo, split=0.03)\n",
    "\n",
    "print(gt_util_train)\n",
    "print(gt_util_val)\n",
    "print(gt_util_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data_svt import GTUtility\n",
    "# gt_util_test = GTUtility('data/SVT/', test=True, polygon=True)\n",
    "\n",
    "# from data_icdar2015fst import GTUtility\n",
    "# gt_util_test = GTUtility('data/ICDAR2015_FST/', test=True, polygon=False)\n",
    "\n",
    "# gt_util_test = GTUtility.merge(gt_util_test1, gt_util_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SegLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model = SL512(input_shape=(384,512,3))\n",
    "model = SL512v2()\n",
    "prior_util = PriorUtil(model)\n",
    "image_size = model.image_size\n",
    "# weights_path = './checkpoints/201807282000_sl_pretrain_fixed_dataset_continutation/weights.010.h5'\n",
    "# weights_path = './cps/sl/original_sl_2013/weights.999.h5'\n",
    "weights_path = './checkpoints/weights.004.h5'\n",
    "# weights_path = './checkpointsw/weights.002.h5'\n",
    "load_weights(model, weights_path)\n",
    "checkdir = os.path.split(weights_path)[0]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_width = 256 #256 \n",
    "input_height = 32 #32\n",
    "crnn_model = CRNNv2((input_width, input_height, 1), len(alphabet), prediction_only=True, gru=False)\n",
    "load_weights(crnn_model, './checkpointsw/201809190735_crnn_fine_tune/weights.080000.h5')\n",
    "# load_weights(crnn_model, './checkpointsw/PRETRAINED WEIGHTS/CRNN_with_LSTM/201806162129_crnn_lstm_synthtext/weights.400000.h5')\n",
    "# crnn_model.summary()\n",
    "# model, model_pred = CRNNv2(input_shape, len(alphabet), gru=False)\n",
    "\n",
    "# freeze = ['conv1_1', 'conv2_1', 'conv3_1', 'conv3_2']\n",
    "\n",
    "# names = [weight.name for layer in crnn_model.layers for weight in layer.weights]\n",
    "# weights = crnn_model.get_weights()\n",
    "\n",
    "# for name, weight in zip(names, weights):\n",
    "#     print(name, weights)\n",
    "#     print(\"========================================================\")\n",
    "\n",
    "# for layer in crnn_model.layers:\n",
    "#     layer.trainable = False\n",
    "    \n",
    "# unfreeze = ['conv4_11111', \n",
    "#             'batchnorm111', \n",
    "#             'act111', \n",
    "#             'conv4_22222', \n",
    "#             'batchnorm222', \n",
    "#             'act222',\n",
    "#             'conv5_11111', \n",
    "#             'batchnorm333',\n",
    "#             'act333',\n",
    "#             'conv5_22222',\n",
    "#             'batchnorm444',\n",
    "#             'act444'\n",
    "#            ]\n",
    "# for layer in crnn_model.layers:\n",
    "#     if layer.name in unfreeze:\n",
    "#         layer.trainable = True\n",
    "\n",
    "# for layer in crnn_model.layers:\n",
    "#     print(layer.name, \"\\t\\t\\t\\t\\t\\t\", layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "images = []\n",
    "images_orig = []\n",
    "data = []\n",
    "\n",
    "# gtu = gt_util_test\n",
    "\n",
    "# for i in np.random.randint(0, gtu.num_samples, 16):    \n",
    "    \n",
    "#     img_path = os.path.join(gtu.image_path, gtu.image_names[i])\n",
    "#     img = cv2.imread(img_path)\n",
    "    \n",
    "#     inputs.append(preprocess(img, image_size))\n",
    "    \n",
    "#     h, w = image_size\n",
    "#     img = cv2.resize(img, (w,h), cv2.INTER_LINEAR).astype('float32')\n",
    "#     img = img[:, :, (2,1,0)]\n",
    "#     img /= 255\n",
    "#     images.append(img)\n",
    "    \n",
    "#     boxes = gtu.data[i]\n",
    "#     data.append(boxes)\n",
    "    \n",
    "# inputs = np.asarray(inputs)\n",
    "# preds = model.predict(inputs, batch_size=1, verbose=1)\n",
    "\n",
    "from skimage import io, color, exposure, transform\n",
    "\n",
    "inputs = []\n",
    "images = []\n",
    "images_orig = []\n",
    "data = []\n",
    "\n",
    "gtu = gt_util_test\n",
    "\n",
    "# np.random.seed(1337)\n",
    "for i in np.random.randint(0, gtu.num_samples, 10):\n",
    "    \n",
    "    img_path = os.path.join(gtu.image_path, gtu.image_names[i])\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "#     hsv = color.rgb2hsv(img) # convert to hsv color space\n",
    "#     hsv[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2]) # \n",
    "#     img = color.hsv2rgb(hsv)\n",
    "    \n",
    "    images_orig.append(np.copy(img))\n",
    "    inputs.append(preprocess(img, image_size))\n",
    "    h, w = image_size\n",
    "    img = cv2.resize(img, (w,h), cv2.INTER_LINEAR).astype('float32') # should we do resizing\n",
    "    img = img[:, :, (2,1,0)] # BGR to RGB\n",
    "    img /= 255\n",
    "    images.append(img)\n",
    "#     boxes = gtu.data[i]\n",
    "#     data.append(boxes)\n",
    "    \n",
    "inputs = np.asarray(inputs)\n",
    "preds = model.predict(inputs, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search to Find Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# steps_seg = np.arange(0.1, 1, 0.1)\n",
    "# steps_lnk = np.arange(0.1, 1, 0.1)\n",
    "\n",
    "# fmes_grid = np.zeros((len(steps_seg),len(steps_lnk)))\n",
    "\n",
    "# '''\n",
    "\n",
    "# def dfs(node, group_id):\n",
    "#     if ids[node] == None:\n",
    "#         ids[node] = group_id\n",
    "#         for a in adjacency[node]:\n",
    "#             dfs(a, group_id)\n",
    "            \n",
    "# '''\n",
    "# ordered = []\n",
    "# for i, segment_threshold in enumerate(steps_seg):\n",
    "#     for j, link_threshold in enumerate(steps_lnk):\n",
    "#         results = [prior_util.decode(p, segment_threshold=segment_threshold, link_threshold=link_threshold) for p in preds]\n",
    "#         TP, FP, FN = evaluate_results(data, results)\n",
    "#         recall = TP / (TP+FN)\n",
    "#         precision = TP / (TP+FP)\n",
    "#         fmes = fscore(precision, recall)\n",
    "#         fmes_grid[i,j] = fmes\n",
    "#         ordered.append([fmes, segment_threshold, link_threshold])\n",
    "# ordered.sort(reverse=True)\n",
    "# for i in range(5):\n",
    "#     print('Segment Threshold: %.2f   Link Threshold: %.2f   F-Score: %.2f' % (ordered[i][1], ordered[i][2], ordered[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for k in range(len(preds)):\n",
    "#     plt.figure(figsize=[12]*2)\n",
    "#     plt.imshow(images[k])\n",
    "#     res = prior_util.decode(preds[k], segment_threshold=0.35, link_threshold=0.25)\n",
    "#     rboxes = res\n",
    "#     if len(rboxes) == 0:\n",
    "#         plt.show()\n",
    "#         continue\n",
    "       \n",
    "#     # ADD A SMALL PADDING TO THE DETECTED BOXES BEFORE RECOGNITION\n",
    "#     bh = rboxes[:,3]\n",
    "#     rboxes[:,2] += bh * 0.2\n",
    "#     rboxes[:,3] += bh * 0.2\n",
    "    \n",
    "#     boxes = []\n",
    "#     for r in rboxes:\n",
    "#         ds = r[:5]\n",
    "#         r2p = rbox_to_polygon(ds)\n",
    "#         boxes.append(r2p)\n",
    "#     boxes = np.asarray(boxes)\n",
    "#     boxes = np.flip(boxes, axis=1) \n",
    "#     boxes = np.reshape(boxes, (-1, 8))\n",
    "    \n",
    "#     # if height is greater than width?\n",
    "#     boxes_mask_a = np.array([b[2] > b[3] for b in rboxes]) \n",
    "#     # if box falls outside frame?\n",
    "#     boxes_mask_b = np.array([not (np.any(b < 0) or np.any(b > image_size[0])) for b in boxes]) \n",
    "#     # merge masks\n",
    "#     boxes_mask = np.logical_and(boxes_mask_a, boxes_mask_b)\n",
    "    \n",
    "#     boxes = boxes[boxes_mask]\n",
    "#     rboxes = rboxes[boxes_mask]\n",
    "#     if len(boxes) == 0:\n",
    "#         boxes = np.empty((0,8))\n",
    "    \n",
    "#     # PLOT BOUNDING BOXES\n",
    "#     for box in boxes:\n",
    "#         plot_box(box, 'polygon', linewidth=5)\n",
    "    \n",
    "#     words = crop_words(img, boxes/image_size[0], input_height, width=input_width, grayscale=True)\n",
    "#     words = np.asarray([w.transpose(1,0,2) for w in words])\n",
    "\n",
    "#     if len(words) > 0:\n",
    "#         res_crnn = crnn_model.predict(words)\n",
    "#     else:\n",
    "#         res_crnn = []\n",
    "\n",
    "#     for i in range(len(res_crnn)):\n",
    "#         chars = [alphabet[c] for c in np.argmax(res_crnn[i], axis=1)]\n",
    "        \n",
    "#         if False:\n",
    "#             img = words[i][:,:,0].T\n",
    "#             plt.figure(figsize=[30,0.5])\n",
    "#             plt.imshow(img, cmap='gray')\n",
    "#             ax = plt.gca()\n",
    "#             ax.get_xaxis().set_visible(False)\n",
    "#             ax.get_yaxis().set_visible(False)\n",
    "#             plt.show()\n",
    "        \n",
    "#         #gt_str = texts[i]\n",
    "#         res_str = decode(chars)\n",
    "        \n",
    "#         #ed = editdistance.eval(gt_str, res_str)\n",
    "#         #ed = levenshtein(gt_str, res_str)\n",
    "#         #ed_norm = ed / len(gt_str)\n",
    "#         #mean_ed += ed\n",
    "#         #mean_ed_norm += ed_norm\n",
    "        \n",
    "#         print('%-20s %s' % (res_str, ''.join(chars)))\n",
    "#         x, y, w, h, theta = rboxes[i][:5]\n",
    "#         plt.text(x+h*np.sin(theta)/2, \n",
    "#                  y+h*np.cos(theta)/2, \n",
    "#                  res_str, \n",
    "#                  rotation=theta/np.pi*180, \n",
    "#                  horizontalalignment='center',\n",
    "#                  verticalalignment='center',\n",
    "#                  fontsize=40, \n",
    "#                  color='r',\n",
    "#                  alpha=1) \n",
    "        \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from crnn_data import crop_words\n",
    "from crnn_utils import decode\n",
    "from sl_utils import rbox_to_polygon, polygon_to_rbox\n",
    "from ssd_viz import plot_box, escape_latex\n",
    "plot_name = 'sl512_crnn_sythtext'\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "for k in range(len(preds)):\n",
    "    plt.figure(figsize=[12]*2)\n",
    "    plt.imshow(images[k])\n",
    "    res = prior_util.decode(preds[k], segment_threshold=0.8, link_threshold=0.5)\n",
    "        \n",
    "    img = images_orig[k]\n",
    "    rboxes = res[:,:5]\n",
    "    if len(rboxes) == 0:\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        continue\n",
    "        \n",
    "    # ADD A SMALL PADDING TO THE DETECTED BOXES BEFORE RECOGNITION\n",
    "    bh = rboxes[:,3]\n",
    "    rboxes[:,2] += bh * 0.1\n",
    "    rboxes[:,3] += bh * 0.2\n",
    "    \n",
    "    boxes = np.asarray([rbox_to_polygon(r) for r in rboxes])\n",
    "    boxes = np.flip(boxes, axis=1) # TODO: fix order of points, why?\n",
    "    boxes = np.reshape(boxes, (-1, 8))\n",
    "    \n",
    "    boxes_mask_a = np.array([b[2] > b[3] for b in rboxes]) # width > height, in square world\n",
    "    boxes_mask_b = np.array([not (np.any(b < 0) or np.any(b > 512)) for b in boxes]) # box inside image\n",
    "    boxes_mask = np.logical_and(boxes_mask_a, boxes_mask_b)\n",
    "    \n",
    "    boxes = boxes[boxes_mask]\n",
    "    rboxes = rboxes[boxes_mask]\n",
    "    if len(boxes) == 0:\n",
    "        boxes = np.empty((0,8))\n",
    "        \n",
    "#     print(boxes)\n",
    "# #     print(\"============================\")\n",
    "    \n",
    "    # PLOT BOUNDING BOXES\n",
    "#     visualize_bounding_box(img, boxes)\n",
    "    \n",
    "    for box in boxes:\n",
    "        for i in range(len(box)):\n",
    "            if i % 2 == 0:\n",
    "                box[i] = box[i]/512\n",
    "            else:\n",
    "                box[i] = box[i]/512\n",
    "    words = crop_words(img, boxes, input_height, width=input_width, grayscale=True)\n",
    "    words = np.asarray([w.transpose(1,0,2) for w in words])\n",
    "#     print('words', words.shape)\n",
    "    if len(words) > 0:\n",
    "        res_crnn = crnn_model.predict(words)\n",
    "    else:\n",
    "        res_crnn = []\n",
    "\n",
    "    #print('rboxes', len(rboxes), 'words', len(words), 'res_crnn', len(res_crnn))\n",
    "    for i in range(len(res_crnn)):\n",
    "        chars = [alphabet[c] for c in np.argmax(res_crnn[i], axis=1)]\n",
    "        \n",
    "        if False:\n",
    "            img = words[i][:,:,0].T\n",
    "            plt.figure(figsize=[30,0.5])\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            ax = plt.gca()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            plt.show()\n",
    "        \n",
    "        #gt_str = texts[i]\n",
    "        res_str = decode(chars)\n",
    "        \n",
    "        #ed = editdistance.eval(gt_str, res_str)\n",
    "        #ed = levenshtein(gt_str, res_str)\n",
    "        #ed_norm = ed / len(gt_str)\n",
    "        #mean_ed += ed\n",
    "        #mean_ed_norm += ed_norm\n",
    "        \n",
    "        #print('%-20s %s' % (res_str, ''.join(chars)))\n",
    "        #print('%s %-20s %0.2f' % (''.join(chars), res_str, res[i,5]))\n",
    "        \n",
    "        #print('%-20s %-20s %s %0.2f' % (\n",
    "        #    gt_str,\n",
    "        #    res_str,\n",
    "        #    ''.join(chars),\n",
    "        #    ed_norm))\n",
    "        x, y, w, h, theta = rboxes[i]\n",
    "        \n",
    "        #res_str = re.sub(r\"([#$%&_{}])\", r\"\\\\\\1\" , res_str)\n",
    "        #print(res_str, '   ', escape_latex(res_str))\n",
    "        \n",
    "#         out_string = escape_latex(res_str)\n",
    "        # pre-processing\n",
    "#         s = out_string.lower()\n",
    "#         s = re.sub(r'[^\\w\\s]','',s)\n",
    "#         s = ''.join([i for i in s if not i.isdigit()])\n",
    "\n",
    "#         possible = []\n",
    "        \n",
    "        # ============ BRANCH 1 ===================\n",
    "#         possible.append(clean.candidates(s))\n",
    "\n",
    "        # # ============ BRANCH 2 ===================\n",
    "        # split_words = infer_spaces(s).split(\" \")\n",
    "        # print(split_words)\n",
    "        # for word in split_words:\n",
    "        # \tpossible.append(candidates(word))\n",
    "\n",
    "        # ============ BRANCH 3 ===================\n",
    "#         for i in range(len(s) + 1):\n",
    "#             possible.append(clean.candidates(s[:i]))\n",
    "#             possible.append(clean.candidates(s[i:]))\n",
    "\n",
    "        # ============ Combine ===================\n",
    "#         possible = [item for sublist in possible for item in sublist]\n",
    "#         print(possible)\n",
    "#         print(most_common(possible))\n",
    "        \n",
    "            \n",
    "            \n",
    "        #plt.text(x+h*np.sin(theta)/2, y+h*np.cos(theta)/2, escape_latex(res_str), rotation=theta/np.pi*180, \n",
    "        #         horizontalalignment='center', size='x-large' , color='cyan') # magenta, lime\n",
    "        plt.text(x+h*np.sin(theta)/2, y+h*np.cos(theta)/2, escape_latex(res_str), rotation=theta/np.pi*180, \n",
    "                 horizontalalignment='center', color='yellow', fontsize=30) # magenta, lime\n",
    "    \n",
    "    plt.axis('off')\n",
    "    \n",
    "    file_name = 'plots/%s_endtoend_realworld_%03i.pgf' % (plot_name, k)\n",
    "    #plt.savefig(file_name, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Video Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(rootpath, filetype):\n",
    "    vids = []\n",
    "    fnames = []\n",
    "    for filename in glob.glob(rootpath + \"*.\" + filetype):\n",
    "        actual_filename = filename.split(\"/\")[-1]\n",
    "        fnames.append(actual_filename.split(\".\")[0])\n",
    "        vids.append(imageio.get_reader(filename,  'ffmpeg'))\n",
    "    fnames, vids = zip(*sorted(zip(fnames, vids)))\n",
    "    return fnames, vids\n",
    "\n",
    "def load_video_gt():\n",
    "    paths = glob.glob(\"./data/fixed_video_gt/Fixed_*.txt\")\n",
    "    paths.sort()\n",
    "    gt = []\n",
    "    for path in paths:\n",
    "        with open(path) as f:\n",
    "            content = f.read().splitlines()\n",
    "        video_gt = []\n",
    "        frame_gt = []\n",
    "        for i in range(len(content)):\n",
    "            if content[i] == \"FRAME\":\n",
    "                video_gt.append(frame_gt)\n",
    "                frame_gt = []\n",
    "            else:\n",
    "                lbl = content[i].split()\n",
    "                lbl = lbl[0].split(\",\")\n",
    "                for i in range(8):\n",
    "                    lbl[i] = float(lbl[i])\n",
    "                frame_gt.append(lbl)\n",
    "        gt.append(video_gt)\n",
    "    return gt\n",
    "\n",
    "video_names, videos = load_video(\"./data/icdar_2015_text_in_video/training/\", \"mp4\")\n",
    "gt = load_video_gt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_video_with_gt(video_path, labels, show_text=False):\n",
    "#     camera = cv2.VideoCapture(video_path)\n",
    "#     fps = camera.get(cv2.CAP_PROP_FPS)\n",
    "#     counter = 0\n",
    "    \n",
    "#     while True:\n",
    "#         (grabbed, frame) = camera.read()\n",
    "        \n",
    "#         if not grabbed:\n",
    "#             break\n",
    "\n",
    "#         frame_labels = labels[counter]\n",
    "#         for label in frame_labels:\n",
    "#             if label[-1] == \"##DONT#CARE##\":\n",
    "#                 continue \n",
    "#             vrx = np.array(label[:8], np.int32)\n",
    "#             vrx = vrx.reshape((-1,1,2))\n",
    "#             frame = cv2.polylines(frame, [vrx], True, (0,255,255),2)\n",
    "            \n",
    "#             if show_text:\n",
    "#                 avg_x = int(round((label[0] + label[2] + label[4] + label[6]) / 4))\n",
    "#                 half_width = int(round((max(label[0], label[2], label[4], label[6]) - min(label[0], label[2], label[4], label[6]))/2))\n",
    "#                 avg_y = int(round((label[1] + label[3] + label[5] + label[7]) / 4))\n",
    "#                 cv2.putText(frame, label[-1], (avg_x-half_width, avg_y+30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "#         cv2.imshow(\"Frame\", frame)\n",
    "#         cv2.waitKey(int(round(1000/fps)))\n",
    "#         counter += 1\n",
    "        \n",
    "#     camera.release()\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "#     cv2.waitKey(1)\n",
    "    \n",
    "# video_index = 1\n",
    "# video_base_path = \"./data/icdar_2015_text_in_video/training/\"\n",
    "# video_format = \".mp4\"\n",
    "# video_path = video_base_path + video_names[video_index] + video_format\n",
    "# show_video_with_gt(video_path, gt[video_index], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    So instead of tracking the 4 coordinates of the bounding box, I should be tracking 'interesting' points on the text\n",
    "    such as the corners. This should yield much better results.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lk_params = dict(winSize = (10, 10), \n",
    "                 maxLevel = 8, \n",
    "                 criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 100, 0.1))\n",
    "\n",
    "def track_point(old_frame, new_frame, old_points):\n",
    "    new_points, status, error = cv2.calcOpticalFlowPyrLK(old_frame, new_frame, old_points, None, **lk_params)\n",
    "    return new_points, status\n",
    "\n",
    "def draw_bounding_box(frame, box, color):\n",
    "    vrx = np.array(box, np.int32)\n",
    "    vrx = vrx.reshape((-1,1,2))\n",
    "    frame = cv2.polylines(frame, [vrx], True, color, 2)\n",
    "    return frame\n",
    "\n",
    "def draw_text(frame, text, box):\n",
    "    avg_x = int(round((box[0] + box[2] + box[4] + box[6]) / 4))\n",
    "    half_width = int(round((max(box[0], box[2], box[4], box[6]) - min(box[0], box[2], box[4], box[6]))/2))\n",
    "    avg_y = int(round((box[1] + box[3] + box[5] + box[7]) / 4))\n",
    "    cv2.putText(frame, text, (avg_x-half_width, avg_y+30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "    \n",
    "def postprocess_detections(preds, segment_threshold=0.4, link_threshold=0.3):\n",
    "    res = prior_util.decode(preds[0], segment_threshold=segment_threshold, link_threshold=link_threshold, debug=False)\n",
    "    rboxes = res\n",
    "    if len(rboxes) == 0:\n",
    "        return []\n",
    "\n",
    "    bh = rboxes[:,3]\n",
    "    rboxes[:,2] += bh * 0.2\n",
    "    rboxes[:,3] += bh * 0.2\n",
    "\n",
    "    boxes = []\n",
    "    for r in rboxes:\n",
    "        ds = r[:5]\n",
    "        r2p = rbox_to_polygon(ds)\n",
    "        boxes.append(r2p)\n",
    "\n",
    "    boxes = np.asarray(boxes)\n",
    "    boxes = np.flip(boxes, axis=1) \n",
    "    boxes = np.reshape(boxes, (-1, 8))\n",
    "\n",
    "    boxes_mask_a = np.array([b[2] > b[3] for b in rboxes]) \n",
    "    boxes_mask_b = np.array([not (np.any(b < 0) or np.any(b > image_size[0])) for b in boxes]) \n",
    "    boxes_mask = np.logical_and(boxes_mask_a, boxes_mask_b)\n",
    "\n",
    "    boxes = boxes[boxes_mask]\n",
    "    rboxes = rboxes[boxes_mask]\n",
    "    if len(boxes) == 0:\n",
    "        boxes = np.empty((0,8))\n",
    "    return boxes\n",
    "\n",
    "def recognize_detected_text(img, boxes):\n",
    "    words = crop_words(img, boxes/image_size[0], input_height, width=input_width, grayscale=True)\n",
    "    words = np.asarray([w.transpose(1,0,2) for w in words])\n",
    "    if len(words) > 0:\n",
    "        res_crnn = crnn_model.predict(words)\n",
    "    else:\n",
    "        res_crnn = []        \n",
    "    recognized_text = []\n",
    "    for i in range(len(res_crnn)):\n",
    "        chars = [alphabet[c] for c in np.argmax(res_crnn[i], axis=1)]\n",
    "        res_str = decode(chars)\n",
    "        recognized_text.append(res_str)\n",
    "    return recognized_text\n",
    "\n",
    "def shift_box(initial_points, new_points, status, box):\n",
    "    delta_x = 0; delta_y = 0\n",
    "    delta_x_list = []; delta_y_list = []\n",
    "    for k in range(len(initial_points)):\n",
    "        if status[k] == 0:\n",
    "            continue\n",
    "        delta_x = delta_x - (initial_points[k][0][0] - new_points[k][0][0])\n",
    "        delta_y = delta_y - (initial_points[k][0][1] - new_points[k][0][1])\n",
    "        delta_x_list.append(delta_x)\n",
    "        delta_y_list.append(delta_y)\n",
    "    delta_x_list.sort()\n",
    "    delta_y_list.sort()\n",
    "    median_delta_x = statistics.median(delta_x_list)\n",
    "    median_delta_y = statistics.median(delta_y_list)\n",
    "    \n",
    "    delta_x = 0; delta_y = 0\n",
    "    THRES = 1.1\n",
    "    for k in range(len(initial_points)):\n",
    "        if status[k] == 0:\n",
    "            continue\n",
    "        if (abs(initial_points[k][0][0] - new_points[k][0][0])) < (abs(THRES * median_delta_x)) and (abs(initial_points[k][0][1] - new_points[k][0][1])) < (abs(THRES * median_delta_y)):\n",
    "            delta_x = delta_x - (initial_points[k][0][0] - new_points[k][0][0])\n",
    "            delta_y = delta_y - (initial_points[k][0][1] - new_points[k][0][1])\n",
    "    mean_delta_x = delta_x / len(initial_points)\n",
    "    mean_delta_y = delta_y / len(initial_points)\n",
    "\n",
    "    shifted_box = [box[0] + mean_delta_x, \n",
    "                   box[1] + mean_delta_y, \n",
    "                   box[2] + mean_delta_x, \n",
    "                   box[3] + mean_delta_y, \n",
    "                   box[4] + mean_delta_x,\n",
    "                   box[5] + mean_delta_y,\n",
    "                   box[6] + mean_delta_x,\n",
    "                   box[7] + mean_delta_y]\n",
    "    \n",
    "    broken = False\n",
    "    for i in range(len(shifted_box)):\n",
    "        if shifted_box[i] < 0:\n",
    "            broken = True\n",
    "        if (i%2 == 0) and (shifted_box[i] > image_size[1]):\n",
    "            broken = True\n",
    "        if (i%2 == 1) and (shifted_box[i] > image_size[0]):\n",
    "            broken = True\n",
    "            \n",
    "    return shifted_box, broken\n",
    "\n",
    "def create_text_mask(frame, box):\n",
    "    mask = np.zeros(frame.shape, dtype=np.uint8)\n",
    "    roi_corners = np.array([[(box[0], box[1]), (box[2], box[3]), (box[4], box[5]), (box[6], box[7])]], dtype=np.int32)\n",
    "    channel_count = frame.shape[2]\n",
    "    ignore_mask_color = (255,)*channel_count\n",
    "    cv2.fillPoly(mask, roi_corners, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(frame, mask)\n",
    "    gray_masked_image = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray_masked_image\n",
    "\n",
    "def create_padded_text_mask(frame, box, padding=10):\n",
    "    mask = np.zeros(frame.shape, dtype=np.uint8)\n",
    "    minX = min([box[0], box[2], box[4], box[6]]) - padding\n",
    "    maxX = max([box[0], box[2], box[4], box[6]]) + padding\n",
    "    minY = min([box[1], box[3], box[5], box[7]]) - padding\n",
    "    maxY = max([box[1], box[3], box[5], box[7]]) + padding\n",
    "    if minX < 0:\n",
    "        minX = 0\n",
    "    if maxX > image_size[1]:\n",
    "        maxX = image_size[1]\n",
    "    if minY < 0:\n",
    "        minY = 0\n",
    "    if maxY > image_size[0]:\n",
    "        maxY = image_size[0]\n",
    "        \n",
    "    roi_corners = np.array([[(minX, minY), (maxX, minY), (maxX, maxY), (minX, maxY)]], dtype=np.int32)\n",
    "    channel_count = frame.shape[2]\n",
    "    ignore_mask_color = (255,)*channel_count\n",
    "    cv2.fillPoly(mask, roi_corners, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(frame, mask)\n",
    "    gray_masked_image = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray_masked_image\n",
    "\n",
    "def generate_initial_tracking_points(frame, box):\n",
    "    gray_masked_image = create_text_mask(frame, box)\n",
    "    corners = cv2.goodFeaturesToTrack(gray_masked_image, 100, minDistance=1, qualityLevel=0.05)\n",
    "    corners = np.int0(corners)\n",
    "    if len(corners) < 10:\n",
    "        return np.array([[]], dtype=np.float32)\n",
    "    pnt_list = []\n",
    "    for corner in corners:\n",
    "        x, y = corner.ravel()\n",
    "        pnt = [x, y]\n",
    "        pnt_list.append(pnt)\n",
    "    initial_points = np.array(pnt_list, dtype=np.float32)\n",
    "    return initial_points.reshape((len(initial_points),1,2))\n",
    "\n",
    "def show_gt(frame, labels, counter, show_text=False):    \n",
    "    frame_labels = labels[counter]\n",
    "    for label in frame_labels:\n",
    "        if label[-1] == \"##DONT#CARE##\":\n",
    "            continue \n",
    "        \n",
    "        vrx = np.array(label[:8], np.int32)\n",
    "        vrx = vrx.reshape((-1,1,2))\n",
    "        frame = cv2.polylines(frame, [vrx], True, (0,255,255),2)\n",
    "        if show_text:\n",
    "            avg_x = int(round((label[0] + label[2] + label[4] + label[6]) / 4))\n",
    "            half_width = int(round((max(label[0], label[2], label[4], label[6]) - min(label[0], label[2], label[4], label[6]))/2))\n",
    "            avg_y = int(round((label[1] + label[3] + label[5] + label[7]) / 4))\n",
    "            cv2.putText(frame, label[-1], (avg_x-half_width, avg_y+30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "def recognize_and_display(img, boxes, frame, show_text=False):\n",
    "    recognized_text = recognize_detected_text(img, boxes)\n",
    "    if show_text:\n",
    "        for i in range(len(recognized_text)):\n",
    "            draw_text(frame, recognized_text[i], boxes[i])\n",
    "\n",
    "def get_orb_features(frame, box, old_frame, new_frame):\n",
    "    orb = cv2.ORB_create()\n",
    "    old_mask = create_text_mask(frame, box)\n",
    "    new_mask = create_padded_text_mask(frame, box, padding=10)\n",
    "    \n",
    "    kp1, des1 = orb.detectAndCompute(new_frame, new_mask)\n",
    "    kp2, des2 = orb.detectAndCompute(old_frame, old_mask)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1,des2)\n",
    "    if len(matches) < 10:\n",
    "        return [], []\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    matches = matches[:10]\n",
    "    \n",
    "    # what if the number of matches is too low or 0?\n",
    "\n",
    "    list_kp1 = []\n",
    "    list_kp2 = []\n",
    "    for mat in matches:\n",
    "        img1_idx = mat.queryIdx\n",
    "        img2_idx = mat.trainIdx\n",
    "        (x1,y1) = kp1[img1_idx].pt\n",
    "        (x2,y2) = kp2[img2_idx].pt\n",
    "        list_kp1.append([x1, y1])\n",
    "        list_kp2.append([x2, y2])\n",
    "    list_kp1 = np.array(list_kp1, dtype=np.float32)\n",
    "    list_kp2 = np.array(list_kp2, dtype=np.float32)\n",
    "    \n",
    "#     for p in range(len(list_kp1)):\n",
    "#         point = list_kp1[p]\n",
    "#         point2 = list_kp2[p]\n",
    "#         cv2.circle(frame, (int(round(point[0])), int(round(point[1]))), 3, (255, 255, 0), -1) # cyan\n",
    "#         cv2.circle(frame, (int(round(point2[0])), int(round(point2[1]))), 3, (0, 255, 255), -1) #yellow\n",
    "\n",
    "    return list_kp1.reshape((len(list_kp1),1,2)), list_kp2.reshape((len(list_kp2),1,2))\n",
    "\n",
    "def track_quadrant(previous_color_frame, previous_gray_frame, current_color_frame, current_gray_frame, quadx, quady):\n",
    "    try:\n",
    "        img = previous_gray_frame[quady:quady+50, quadx:quadx+50]\n",
    "        corners = cv2.goodFeaturesToTrack(img, 100, minDistance=1, qualityLevel=0.05)\n",
    "        corners = np.int0(corners)\n",
    "        if len(corners) < 10:\n",
    "            return 999,999\n",
    "        pnt_list = []\n",
    "        for corner in corners:\n",
    "            x, y = corner.ravel()\n",
    "            pnt = [x, y]\n",
    "            pnt_list.append(pnt)\n",
    "        initial_points = np.array(pnt_list, dtype=np.float32)\n",
    "        initial_points = initial_points.reshape((len(initial_points),1,2))\n",
    "        if len(initial_points) == 0:\n",
    "            return 999,999\n",
    "        d_new_points, d_status, d_error = cv2.calcOpticalFlowPyrLK(previous_gray_frame, current_gray_frame, initial_points, None, **lk_params)\n",
    "\n",
    "        delta_x = 0; delta_y = 0\n",
    "        delta_x_list = []; delta_y_list = []\n",
    "        for k in range(len(initial_points)):\n",
    "            if d_status[k] == 0:\n",
    "                continue\n",
    "            delta_x = delta_x - (initial_points[k][0][0] - d_new_points[k][0][0])\n",
    "            delta_y = delta_y - (initial_points[k][0][1] - d_new_points[k][0][1])\n",
    "            delta_x_list.append(delta_x)\n",
    "            delta_y_list.append(delta_y)\n",
    "        delta_x_list.sort()\n",
    "        delta_y_list.sort()\n",
    "        median_delta_x = statistics.median(delta_x_list)\n",
    "        median_delta_y = statistics.median(delta_y_list)\n",
    "\n",
    "        delta_x = 0; delta_y = 0\n",
    "        THRES = 1.1\n",
    "        for k in range(len(initial_points)):\n",
    "            if d_status[k] == 0:\n",
    "                continue\n",
    "            if (abs(initial_points[k][0][0] - d_new_points[k][0][0])) < (abs(THRES * median_delta_x)) and (abs(initial_points[k][0][1] - d_new_points[k][0][1])) < (abs(THRES * median_delta_y)):\n",
    "                delta_x = delta_x - (initial_points[k][0][0] - d_new_points[k][0][0])\n",
    "                delta_y = delta_y - (initial_points[k][0][1] - d_new_points[k][0][1])\n",
    "        mean_delta_x = delta_x / len(initial_points)\n",
    "        mean_delta_y = delta_y / len(initial_points)\n",
    "        return mean_delta_x, mean_delta_y\n",
    "    except:\n",
    "        return 999,999\n",
    "        \n",
    "def show_video_with_preds(video_path, labels, show_text=False):\n",
    "    camera = cv2.VideoCapture(video_path)\n",
    "    total_frame_count = int(camera.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    old_points = np.array([[]])\n",
    "    _, frame = camera.read()\n",
    "    old_color_frame = cv2.resize(frame, (image_size[1], image_size[0]))\n",
    "    old_gray_frame = cv2.cvtColor(old_color_frame, cv2.COLOR_BGR2GRAY)\n",
    "    fps = camera.get(cv2.CAP_PROP_FPS)\n",
    "    COUNTER = 1\n",
    "    LAST_FRAME_NUMBER_WITH_DETECTION = -4\n",
    "    NUMBER_OF_FRAMES_SINCE_LAST_DETECTION = 0\n",
    "    old_boxes = []\n",
    "    totalX = 0; totalY = 0\n",
    "    \n",
    "    while True:\n",
    "        (grabbed, frame) = camera.read()\n",
    "        if not grabbed:\n",
    "            break\n",
    "        \n",
    "        current_color_frame = cv2.resize(frame, (image_size[1], image_size[1]))\n",
    "        current_color_frame_copy = current_color_frame.copy()\n",
    "        current_gray_frame = cv2.cvtColor(current_color_frame, cv2.COLOR_BGR2GRAY)\n",
    "        NUMBER_OF_FRAMES_SINCE_LAST_DETECTION = COUNTER - LAST_FRAME_NUMBER_WITH_DETECTION\n",
    "        \n",
    "        start = time.time()\n",
    "        a = cv2.resize(old_gray_frame, (150, 150))\n",
    "        b = cv2.resize(current_gray_frame, (150, 150))\n",
    "        c = cv2.resize(old_color_frame, (150, 150))\n",
    "        d = cv2.resize(current_color_frame, (150, 150))\n",
    "        \n",
    "        x1, y1 = track_quadrant(c, a, d, b, 0, 0)\n",
    "        x2, y2 = track_quadrant(c, a, d, b, 50, 0)\n",
    "        x3, y3 = track_quadrant(c, a, d, b, 100, 0)\n",
    "        x4, y4 = track_quadrant(c, a, d, b, 0, 50)\n",
    "        x5, y5 = track_quadrant(c, a, d, b, 50, 50)\n",
    "        x6, y6 = track_quadrant(c, a, d, b, 100, 50)\n",
    "        x7, y7 = track_quadrant(c, a, d, b, 0, 100)\n",
    "        x8, y8 = track_quadrant(c, a, d, b, 50, 100)\n",
    "        x9, y9 = track_quadrant(c, a, d, b, 100, 100)\n",
    "        \n",
    "#         print(x1,y1)\n",
    "#         print(x2,y2)\n",
    "#         print(x3,y3)\n",
    "#         print(x4,y4)\n",
    "#         print(x5,y5)\n",
    "#         print(x6,y6)\n",
    "#         print(x7,y7)\n",
    "#         print(x8,y8)\n",
    "#         print(x9,y9)\n",
    "\n",
    "        '''\n",
    "        Need to add up the total change\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        if x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 < 600 and y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9 < 600:\n",
    "            threshold = 10\n",
    "            strong_right = False; strong_left = False; strong_down = False; strong_up = False\n",
    "            weak_right = False; weak_left = False; weak_down = False; weak_up = False\n",
    "            if x1 > 0 and x2 > 0 and x3 > 0 and x4 > 0 and x5 > 0 and x6 > 0 and x7 > 0 and x8 > 0 and x9:\n",
    "                avgX = (x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9) / 9\n",
    "                if avgX > threshold:\n",
    "                    strong_right = True\n",
    "                else:\n",
    "                    weak_right = True\n",
    "\n",
    "            elif x1 < 0 and x2 < 0 and x3 < 0 and x4 < 0 and x5 < 0 and x6 < 0 and x7 < 0 and x8 < 0 and x9:\n",
    "                avgX = (x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9) / 9\n",
    "                if avgX > -threshold:\n",
    "                    strong_left = True\n",
    "                else:\n",
    "                    weak_left = True\n",
    "\n",
    "            if y1 > 0 and y2 > 0 and y3 > 0 and y4 > 0 and y5 > 0 and y6 > 0 and y7 > 0 and y8 > 0 and y9:\n",
    "                avgY = (y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9) / 9\n",
    "                if avgY > threshold:\n",
    "                    strong_down = True\n",
    "                else:\n",
    "                    weak_down = True\n",
    "\n",
    "            elif y1 < 0 and y2 < 0 and y3 < 0 and y4 < 0 and y5 < 0 and y6 < 0 and y7 < 0 and y8 < 0 and y9:\n",
    "                avgY = (y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9) / 9\n",
    "                if avgY > -threshold:\n",
    "                    strong_up = True\n",
    "                else:\n",
    "                    weak_up = True\n",
    "\n",
    "            if strong_right and weak_down and weak_up:\n",
    "                print(\"RIGHT\")\n",
    "                ratio = avgX / 150\n",
    "                ratio = ratio * 512\n",
    "                section = int(128 * round(float(ratio)/128))\n",
    "                cropped_image = current_color_frame[0:512, section:512]\n",
    "            elif strong_left and weak_down and weak_up:\n",
    "                print(\"LEFT\")\n",
    "                ratio = avgX / 150\n",
    "                ratio = ratio * 512\n",
    "                section = int(128 * round(float(ratio)/128))\n",
    "                cropped_image = current_color_frame[0:512, 0:512-section]\n",
    "            elif strong_down and weak_left and weak_right:\n",
    "                print(\"DOWN\")\n",
    "                ratio = avgY / 150\n",
    "                ratio = ratio * 512\n",
    "                section = int(128 * round(float(ratio)/128))\n",
    "                cropped_image = current_color_frame[section:512, 0:512]\n",
    "            elif strong_up and weak_left and weak_right:\n",
    "                print(\"UP\")\n",
    "                ratio = avgY / 150\n",
    "                ratio = ratio * 512\n",
    "                section = int(128 * round(float(ratio)/128))\n",
    "                cropped_image = current_color_frame[0:512-section, 0:512]\n",
    "            \n",
    "        '''\n",
    "        if all moving inwards:\n",
    "            no need to detect anything\n",
    "        if all moving outwards\n",
    "            no need to detect the center\n",
    "        if not moving\n",
    "            no need to detect\n",
    "        '''\n",
    "        \n",
    "        print(\"took:\", time.time()-start)\n",
    "        \n",
    "        if NUMBER_OF_FRAMES_SINCE_LAST_DETECTION > 3:\n",
    "            inputs = np.asarray([preprocess(current_color_frame, image_size)])\n",
    "            preds = model.predict(inputs, batch_size=1, verbose=1)\n",
    "            boxes = postprocess_detections(preds, segment_threshold=0.6, link_threshold=0.2)\n",
    "            if len(boxes) > 0:\n",
    "                LAST_FRAME_NUMBER_WITH_DETECTION = COUNTER\n",
    "                for box in boxes:\n",
    "                    current_color_frame = draw_bounding_box(current_color_frame, box, (0,0,255))\n",
    "                    current_color_frame_copy = draw_bounding_box(current_color_frame_copy, box, (255,0,255))\n",
    "                old_boxes = boxes\n",
    "                recognize_and_display(img, boxes, current_color_frame, show_text=show_text)\n",
    "    \n",
    "        else:                    \n",
    "            if len(old_boxes) > 0:\n",
    "                all_boxes = []\n",
    "                for box in old_boxes:\n",
    "                    try:\n",
    "                        initial_points = generate_initial_tracking_points(old_color_frame, box)\n",
    "                        if len(initial_points) == 0:\n",
    "                            continue\n",
    "                        for pt in initial_points:\n",
    "                            cv2.circle(old_color_frame,(pt[0][0], pt[0][1]), 3, (255,255,0), -1)\n",
    "                        new_points, status = track_point(old_gray_frame, current_gray_frame, initial_points)\n",
    "                        for i in range(len(new_points)):\n",
    "                            if status[i] == 1:\n",
    "                                cv2.circle(current_color_frame,(new_points[i][0][0], new_points[i][0][1]), 3, (0,255,255), -1)\n",
    "                        shifted_box, broken = shift_box(initial_points, new_points, status, box)\n",
    "                        if broken:\n",
    "                            continue\n",
    "                        current_color_frame = draw_bounding_box(current_color_frame, shifted_box, (0,255,0))\n",
    "                        all_boxes.append(shifted_box)\n",
    "                        old_boxes = np.array(all_boxes)\n",
    "                        recognize_and_display(img, boxes, current_color_frame, show_text=show_text)\n",
    "                    except:\n",
    "                        LAST_FRAME_NUMBER_WITH_DETECTION = COUNTER -5\n",
    "                        break\n",
    "        \n",
    "#         cv2.imshow(\"Current Frame\", current_color_frame)\n",
    "#         cv2.imshow(\"Previous Frame\", old_color_frame)\n",
    "        old_color_frame = current_color_frame_copy.copy()\n",
    "        old_gray_frame = current_gray_frame.copy()\n",
    "        cv2.waitKey(10)\n",
    "        COUNTER += 1\n",
    "        \n",
    "    camera.release()\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "video_index = 14\n",
    "video_path = \"./data/icdar_2015_text_in_video/training/\" + video_names[video_index] + \".mp4\"\n",
    "show_video_with_preds(video_path, gt[video_index], show_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             if len(old_boxes1) > 0:\n",
    "#                 all_boxes1 = []\n",
    "#                 for box in old_boxes1:\n",
    "#                     start = time.time()\n",
    "#                     try:\n",
    "#                         list_kp1, list_kp2 = get_orb_features(frame, box, old_frame, new_frame)\n",
    "#                         if len(list_kp1) == 0:\n",
    "#                             LAST_FRAME_NUMBER_WITH_DETECTION = -5\n",
    "#                             continue\n",
    "#                         dummy_status = [1] * len(list_kp1)\n",
    "#     #                     initial_points = generate_initial_tracking_points(frame, box)\n",
    "#     #                     new_points, status = track_point(old_frame, new_frame, initial_points)\n",
    "#     #                     shifted_box = shift_box(initial_points, new_points, status, box)\n",
    "#     #                     frame = draw_bounding_box(frame, shifted_box, True)\n",
    "#                         shifted_box1, broken = shift_box(list_kp2, list_kp1, dummy_status, box)\n",
    "#                         if broken:\n",
    "#                             continue\n",
    "#                         frame = draw_bounding_box(frame, shifted_box1, (255,0,0))\n",
    "#                         all_boxes1.append(shifted_box1)\n",
    "#                         old_boxes1 = np.array(all_boxes1)\n",
    "#                         recognize_and_display(img, boxes, frame, show_text=show_text)\n",
    "#                     except:\n",
    "#                         print(\"HIT ERROR\")\n",
    "#                         LAST_FRAME_NUMBER_WITH_DETECTION = COUNTER -5\n",
    "#                         break\n",
    "#                     end = time.time()\n",
    "#                     print(\"[info] orb took:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                     for p in range(len(new_points)):\n",
    "#                         x, y = new_points[p].ravel()\n",
    "#                         a, b = initial_points[p].ravel()\n",
    "#                         if status[p][0] == 0:\n",
    "#                             continue\n",
    "#                         cv2.circle(frame, (x, y), 3, (255, 255, 0), -1)\n",
    "#                         cv2.circle(frame, (a, b), 3, (0, 255, 255), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create old frame\n",
    "# _, frame = camera.read()\n",
    "# old_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# # Lucas kanade params\n",
    "# lk_params = dict(winSize = (15, 15), maxLevel = 4, criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    " \n",
    "# # Mouse function\n",
    "# def select_point(event, x, y, flags, params):\n",
    "#     global point, point_selected, old_points\n",
    "#     if event == cv2.EVENT_LBUTTONDOWN:\n",
    "#         point = (x, y)\n",
    "#         point_selected = True\n",
    "#         old_points = np.array([[x, y]], dtype=np.float32)\n",
    " \n",
    "# cv2.namedWindow(\"Frame\")\n",
    "# cv2.setMouseCallback(\"Frame\", select_point)\n",
    " \n",
    "# point_selected = False\n",
    "# point = ()\n",
    "# old_points = np.array([[]])\n",
    "# while True:\n",
    "#     _, frame = camera.read()\n",
    "#     gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "#     if point_selected is True:\n",
    "#         cv2.circle(frame, point, 5, (0, 0, 255), 2)\n",
    " \n",
    "#         new_points, status, error = cv2.calcOpticalFlowPyrLK(old_frame, gray_frame, old_points, None, **lk_params)\n",
    "#         old_frame = gray_frame.copy()\n",
    "#         old_points = new_points\n",
    " \n",
    "#         x, y = new_points.ravel()\n",
    "#         cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    " \n",
    " \n",
    " \n",
    "#     cv2.imshow(\"Frame\", frame)\n",
    " \n",
    "#     key = cv2.waitKey(1)\n",
    "#     if key == 27:\n",
    "#         break\n",
    " \n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lk_params = dict(winSize = (15, 15), \n",
    "#                  maxLevel = 2, \n",
    "#                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# def track_point(old_frame, new_frame, old_points):\n",
    "#     new_points, status, error = cv2.calcOpticalFlowPyrLK(old_frame, new_frame, old_points, None, **lk_params)\n",
    "#     old_frame = new_frame.copy()\n",
    "#     old_points = new_points\n",
    "#     x, y = new_points.ravel()\n",
    "#     return x, y, old_frame\n",
    "\n",
    "# def draw_bounding_box(frame, box):\n",
    "#     vrx = np.array(box, np.int32)\n",
    "#     vrx = vrx.reshape((-1,1,2))\n",
    "#     frame = cv2.polylines(frame, [vrx], True, (0,255,255),2)\n",
    "#     return frame\n",
    "\n",
    "# def draw_text(frame, text, box):\n",
    "#     avg_x = int(round((box[0] + box[2] + box[4] + box[6]) / 4))\n",
    "#     half_width = int(round((max(box[0], box[2], box[4], box[6]) - min(box[0], box[2], box[4], box[6]))/2))\n",
    "#     avg_y = int(round((box[1] + box[3] + box[5] + box[7]) / 4))\n",
    "#     cv2.putText(frame, text, (avg_x-half_width, avg_y+30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "    \n",
    "# def postprocess_detections(preds, segment_threshold=0.5, link_threshold=0.5):\n",
    "#     res = prior_util.decode(preds[0], segment_threshold=0.7, link_threshold=0.6, debug=False)\n",
    "#     rboxes = res\n",
    "#     if len(rboxes) == 0:\n",
    "#         return []\n",
    "\n",
    "#     bh = rboxes[:,3]\n",
    "#     rboxes[:,2] += bh * 0.2\n",
    "#     rboxes[:,3] += bh * 0.2\n",
    "\n",
    "#     boxes = []\n",
    "#     for r in rboxes:\n",
    "#         ds = r[:5]\n",
    "#         r2p = rbox_to_polygon(ds)\n",
    "#         boxes.append(r2p)\n",
    "\n",
    "#     boxes = np.asarray(boxes)\n",
    "#     boxes = np.flip(boxes, axis=1) \n",
    "#     boxes = np.reshape(boxes, (-1, 8))\n",
    "\n",
    "#     boxes_mask_a = np.array([b[2] > b[3] for b in rboxes]) \n",
    "#     boxes_mask_b = np.array([not (np.any(b < 0) or np.any(b > 512)) for b in boxes]) \n",
    "#     boxes_mask = np.logical_and(boxes_mask_a, boxes_mask_b)\n",
    "\n",
    "#     boxes = boxes[boxes_mask]\n",
    "#     rboxes = rboxes[boxes_mask]\n",
    "#     if len(boxes) == 0:\n",
    "#         boxes = np.empty((0,8))\n",
    "#     return boxes\n",
    "\n",
    "\n",
    "\n",
    "# def show_video_with_preds(video_path, labels, show_text=False, track=False):\n",
    "    \n",
    "#     camera = cv2.VideoCapture(video_path)\n",
    "#     old_points = np.array([[]])\n",
    "#     _, frame = camera.read()\n",
    "#     frame = cv2.resize(frame, (300, 300))\n",
    "#     old_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     fps = camera.get(cv2.CAP_PROP_FPS)\n",
    "#     counter = 0\n",
    "#     detected_on_frame = 0\n",
    "#     tracked_on_frame = 0\n",
    "    \n",
    "#     while True:\n",
    "#         (grabbed, frame) = camera.read()\n",
    "        \n",
    "#         if not grabbed:\n",
    "#             break\n",
    "\n",
    "#         frame = cv2.resize(frame, (300, 300))\n",
    "#         new_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "#         inputs = []\n",
    "#         inputs.append(preprocess(frame, image_size))\n",
    "#         inputs = np.asarray(inputs)\n",
    "#         preds = model.predict(inputs, batch_size=1, verbose=1)\n",
    "\n",
    "#         boxes = postprocess_detections(preds, segment_threshold=0.5, link_threshold=0.5)\n",
    "#         for box in boxes:\n",
    "#             print(box)\n",
    "#         print(\"-\"*100)\n",
    "        \n",
    "#         for i in range(len(preds)):\n",
    "#             res = prior_util.decode(preds[i], segment_threshold=0.7, link_threshold=0.6, debug=False)\n",
    "#             rboxes = res\n",
    "#             if len(rboxes) == 0:\n",
    "#                 continue\n",
    "\n",
    "#             bh = rboxes[:,3]\n",
    "#             rboxes[:,2] += bh * 0.2\n",
    "#             rboxes[:,3] += bh * 0.2\n",
    "\n",
    "#             boxes = []\n",
    "#             for r in rboxes:\n",
    "#                 ds = r[:5]\n",
    "#                 r2p = rbox_to_polygon(ds)\n",
    "#                 boxes.append(r2p)\n",
    "                \n",
    "#             boxes = np.asarray(boxes)\n",
    "#             boxes = np.flip(boxes, axis=1) \n",
    "#             boxes = np.reshape(boxes, (-1, 8))\n",
    "\n",
    "#             boxes_mask_a = np.array([b[2] > b[3] for b in rboxes]) \n",
    "#             boxes_mask_b = np.array([not (np.any(b < 0) or np.any(b > 512)) for b in boxes]) \n",
    "#             boxes_mask = np.logical_and(boxes_mask_a, boxes_mask_b)\n",
    "\n",
    "#             boxes = boxes[boxes_mask]\n",
    "#             rboxes = rboxes[boxes_mask]\n",
    "#             if len(boxes) == 0:\n",
    "#                 boxes = np.empty((0,8))\n",
    "\n",
    "#             for box in boxes:\n",
    "#                 if track:\n",
    "#                     center_x = round((box[0] + box[2] + box[4] + box[6]) / 4.0)\n",
    "#                     center_y = round((box[1] + box[3] + box[5] + box[7]) / 4.0)\n",
    "#                     old_points = np.array([[center_x, center_y]], dtype=np.float32)\n",
    "#                     x, y, old_frame = track_point(old_frame, new_frame, old_points)\n",
    "#                     cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "\n",
    "#                 frame = draw_bounding_box(frame, box)\n",
    "                \n",
    "#             words = crop_words(img, boxes/300, input_height, width=input_width, grayscale=True)\n",
    "#             words = np.asarray([w.transpose(1,0,2) for w in words])\n",
    "\n",
    "#             if len(words) > 0:\n",
    "#                 res_crnn = crnn_model.predict(words)\n",
    "#             else:\n",
    "#                 res_crnn = []\n",
    "\n",
    "#             if show_text:\n",
    "#                 for i in range(len(res_crnn)):\n",
    "#                     chars = [alphabet[c] for c in np.argmax(res_crnn[i], axis=1)]\n",
    "#                     res_str = decode(chars)\n",
    "#                     draw_text(frame, res_str, boxes[i])\n",
    "                    \n",
    "#         cv2.imshow(\"Frame\", frame)\n",
    "#         cv2.waitKey(1)\n",
    "#         counter += 1\n",
    "        \n",
    "#     camera.release()\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "#     cv2.waitKey(1)\n",
    "\n",
    "# video_index = 14\n",
    "# video_base_path = \"./data/icdar_2015_text_in_video/training/\"\n",
    "# video_format = \".mp4\"\n",
    "# video_path = video_base_path + video_names[video_index] + video_format\n",
    "# show_video_with_preds(video_path, gt[video_index], True, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
